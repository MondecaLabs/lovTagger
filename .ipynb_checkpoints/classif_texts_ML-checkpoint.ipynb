{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mondeca/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate, cross_val_predict\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier    \n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, cohen_kappa_score, classification_report , precision_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('DATA.pkl', 'rb') as handle:\n",
    "    X, Y, vocabs = pickle.load(handle)\n",
    "    \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Legal Agent. The AKT Reference Ontology has been designed to support the AKT-2 demonstrator (\"AKTive Portal\"), and subsequent activities. The ontology, designed by the AKT-2 group and codified by Enrico Motta, extends Version 1. we have decided that a publication reference is an intangible, abstract information. medium. SME are important, so we define a class to represent them explicitly. In some case we might not know or we do not want to bother specifying excatly whether something is a small-organization or a medium-organization. Hence, we can just say \\'x is a SME\\' without going into further detail. Some agents have legal status: definitely organizations and people, anybody else?. People and in general even organizations and organization units may have research interests.  This relation shoudl be used to specify them. Generic Agent. This notion comes from Cyc.  It is useful to group together all information bearing entities, including video, audio and documents. An information bearing object may have an author (a generic agent) and may be owned by a legal agent. It is a tangible object. An organization which has a political connotation. An organization with more than 250 employees. large. A publication which contains items which cane be themselves referenced through a publication reference.  Composite publications include newspapers, magazines and journals. A book which is a collection of articles is a composite publication, a monograph is not. Organization. This is a generic notion, an agent can be an organization, a person an animal, a software agent, etc. An organization with no more than 10 employees.  It also has to be independent, i.e., less than 25% owned by one enterprise (or jointly by several enterprises) falling outside the definition of micro-sized enterprise. A generalized transfer in which information is passed from main agent to one or more recipient agents.  Examples include giving a tutorial. A generic class for addresses, whether email or postal. We see an address as abstract information and therefore it is an intangible thing. By technology we mean engineered applications of science. I guess we are probably confining ourselves to tangible things but as I am not sure I will use thing as the direct superclass - e.g., an algorithm is an intangible thing, but it could be seen as a technology, if we give a broad interpretation of the term. A web browser is not a web-based system!. Whether the software is released, alpha or beta. An organization is a type of legal agent. A degree is type of award. has web address. has email address. This is a generic class to catch all sorts of borderline and metaphorical ways to carry things from A to B. Any kind of recorded audio, which is tangible.  This also includes a audio file on a machine. We use EU guidelines to distinguish between different organization sizes. A person which has an affiliation with some organization. For instance employees are affiliated to the organization they work for, students to the institution where they are studying, etc. A person can have multiple affiliations, which means that there is no constraint relating the values of slot has-affiliation-to-unit to the values of slot has-affiliation. What is being transferred. Merrian-Webster has a good set of definitions for a method. They say it is \\'a systematic procedure, technique, or mode of inquiry employed by or proper to a particular discipline or art;  a systematic plan followed in presenting material for instruction; a way, technique, or process of or for doing something; a body of skills or techniques\\'. This is very much also what we mean by method. A generic class to specify generic areas for research or business initiatives. For instance, the area in which a project is situated. A system which is accessible through the web. This is a minimalist definition of class event.  We start with the very basic and we will then add slots as we specialise this definition for specific classes of events. The fillers of slots has-other-agents-involved and has-main-agent should not intersect. Other agents involved in the event. This is an event in which the main agent (plus maybe others) goes from some place to another. An organization with over 10000 employees. HPKB says that genders are intangible..Uhm... The agents causing the event to happen, if they are known. This comes from the ontolingua library. A periodical-publication is published regularly, such as once every week.  Strictly speaking, the noun \\'periodical\\' is used by librarians to refer to things published at intervals of greater than a day.  We use the phase periodical-publication to include newspapers and other daily publications, since they share many bibliographic features. The periodicity indicates how often the publication comes out. Note that this is a duration, rather than a time interval. A time interval indicates a specific time interval on the time continuum, so we need to model periodicity as a time quantity. A publication is something which has one or more publication references. A publication can be both an article in a journal or a journal itself. The distinction between publication and publication-reference makes it possible to distinguish between multiple occurrences of the sam publication, for instance in different media. Something tangible designed to transport people, animals, objects from A to B. For instance a bycicle, a car, a boat, etc. An event in which the main agent transfers something (the thing-acted-on, tangible or intangible) to one or more recipient agents. Note that we do not say anything about whether the original agent still retain the thing-acted-on.  In some cases this is clearly true (\\'I pass my wisdom on to my daughter\\'), in other cases it is not (I give you my wallet). A geopolitical entity is a geographical area which is associated with some sort of political structure. For instance, Russia, Italy, The-city-of-Messina, etc. A geopolitical entity can be also seen as an agent - e.g., France declared war to Spain. Organization Size. micro. Legal agents can be either organizations or people. An awarding body is normally an organization, an individual, or a bunch of people. a generalized transfer in which information is passed from main agent to one or more recipient agents.  examples include giving a tutorial. An award is an intangible thing, even if the piece of paper which is often associated with an award is tangible.  What about the virtual piece of paper in the virtual degree ceremony?  I guess that ought to be an intangible. small. AKT Reference Ontology (Portal Ontology). An organization with no more than 50 employees.  It also has to be independent, i.e., less than 25% owned by one enterprise (or jointly by several enterprises) falling outside the definition of small-sized enterprise. Finally, either the turnover total must be less than 7M Euros or the balance sheet total must be less than 5M Euros. An organization with no more than 250 employees.  It also has to be independent, i.e., less than 25% owned by one enterprise (or jointly by several enterprises) falling outside the definition of medium-sized enterprise. Finally, either the turnover total must be less than 40M Euros or the balance sheet total must be less than 27M Euros. very large. The agents which receive the thing-acted-on. Political Organization. A meeting type of event. Note that both attendee and organizer have multiple cardinality. This used to be called periodical publication.  However, many periodicals do not appear at fixed intervals, which is why librarians refer to them as serials. So, we now use the concept of serial publication and the has-periodicity slot has been removed. Small or Medium-sized Organization. An organization may have a number of units. Units may themselves have sub-units. The location at which an event takes place. Modified to allow addresses to be given as strings, with no structure. Any kind of recorded video, which is tangible.  This also includes a mpeg file on a machine. When something is produced. Information in general, independent of an object in which it is encoded. Whatever is transferred in an information-transfer event. It is clearly an intangible thing. A generic class for locations.  It includes both real and fantastic places. \\'Real\\' geographical regions. A partnership is not necessarily a company, e.g. a consultancy firm is not a company. It is sufficient that somebody in unit ?u works in project ?p. '"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656 656 656\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(Y), len(vocabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "totals = Counter(i for i in list(itertools.chain.from_iterable(Y)))\n",
    "distrib = dict(totals)\n",
    "#distrib = sorted(distrib.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags_len = np.sum(list(distrib.values()))\n",
    "distrib_freq = {key:val/all_tags_len for key,val in distrib.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(distrib.keys(), distrib.values())\n",
    "plt.xticks(rotation='vertical')\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the number of uppercase in string\n",
    "def num_uppercase(string):\n",
    "    count = 0\n",
    "    for l in string:\n",
    "        if l.isupper():\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# From a list of words, split the words with more than one uppercase\n",
    "def split_uppercases(words):\n",
    "    words_proc = []\n",
    "    for word in words:\n",
    "        if num_uppercase(word) >= 1 and not(word.isupper()):\n",
    "            splitted_words = re.findall('[A-Za-z][a-z]*', word)\n",
    "            for w in splitted_words:\n",
    "                words_proc.append(w.lower())\n",
    "        else:\n",
    "            words_proc.append(word.lower())\n",
    "    return words_proc\n",
    "\n",
    "# Tokenizer\n",
    "def Tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    return words\n",
    "\n",
    "# Tokenizer : Utilise stems of words\n",
    "def Tokenizer_lemm(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    porter_stemmer=nltk.PorterStemmer()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "# new Tokenizer : split the strings in the form \"jointAnnual\" with a space in the text\n",
    "def newTokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).split()\n",
    "    words = split_uppercases(words)\n",
    "    #porter_stemmer=nltk.PorterStemmer()\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    #words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('description', 'description'),\n",
       " ('knowledgegrouping', 'knowledge'),\n",
       " ('organization', 'grouping'),\n",
       " ('division', 'organization'),\n",
       " ('organizationalunit', 'division'),\n",
       " ('teaches', 'organizational'),\n",
       " ('institution', 'unit'),\n",
       " ('html', 'teaches'),\n",
       " ('subject', 'institution'),\n",
       " ('knowledgegrouping', 'html')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare both tokenizer\n",
    "[(x,y) for x,y in zip(Tokenizer(X[10]), newTokenizer(X[10]))][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.25, max_features=None, min_df=0.0025,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function Tokenizer at 0x7f1041ff2ae8>, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Study the CountVectorizer\n",
    "CV = CountVectorizer(tokenizer=Tokenizer, min_df=.0025, max_df=0.25, ngram_range=(1,3))\n",
    "CV.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(CV.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline : Vectorizer + tfidf + SVD\n",
    "pipeline1 = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer_lemm, min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=100, random_state=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of classifiers which work with multilabels\n",
    "clfs = {\n",
    "'RF': RandomForestClassifier(n_estimators=100, random_state=1, n_jobs=50),\n",
    "'MLP': MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(100),random_state=1),\n",
    "'KPPV': KNeighborsClassifier(n_neighbors=7)\n",
    "}\n",
    "\n",
    "# Fonction de test des diffÃ©rents classifieurs\n",
    "def run_classifiers(clfs,X,Y, pipeline):\n",
    "    # Apply processing pipeline\n",
    "    X_proc = pipeline.fit_transform(X)\n",
    "    # Cross Validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    scoring = ['precision_macro', 'recall_macro', 'f1_macro', 'precision_micro', 'recall_micro']\n",
    "    for i in clfs:\n",
    "        try:\n",
    "            clf = clfs[i]\n",
    "            print(\"\\n\\n======= {0} =======\".format(i))\n",
    "            y_pred = cross_val_predict(clf, X_proc, Y, cv=kf)\n",
    "            print(classification_report(Y, y_pred))            \n",
    "#             scores = cross_validate(clf, X_proc, Y, cv=kf, scoring=scoring)\n",
    "#             print(\"mean execution time : \", np.mean(scores['fit_time'] + scores['score_time']))\n",
    "#             #y_pred = cross_val_predict(clf, X_proc, Y, cv=kf)\n",
    "#             #print(y_pred)\n",
    "#             print(\"mean f1 : \",np.mean(scores['test_f1_macro']))\n",
    "#             print(\"mean precision : \",np.mean(scores['test_precision_macro']))\n",
    "#             print(\"mean recall : \",np.mean(scores['test_recall_macro']))\n",
    "#             print(\"mean precision : \",np.mean(scores['test_precision_micro']))\n",
    "#             print(\"mean recall : \",np.mean(scores['test_recall_micro']))\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform multilablels Y in sparse matrix for sklearn\n",
    "mlb = MultiLabelBinarizer(sparse_output=False)\n",
    "Y_mlb = mlb.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the tags with a low frequency inferior of seuil\n",
    "# Some graphs will then not have any tags anymore, these graphs are the removed\n",
    "def remove_low_frequencies(X, Y_mlb, vocabs, seuil = 0.02):\n",
    "    labels_freqs = np.sum(Y_mlb, axis = 0) / np.sum(Y_mlb)\n",
    "    # Keeps only labels with freq > seuil\n",
    "    inds_col = labels_freqs > seuil\n",
    "    Y_filt = Y_mlb * inds_col\n",
    "    \n",
    "    inds_0_col = np.where((Y_filt == 0).all(axis=0))[0]\n",
    "    mask0 = np.ones(Y_filt.shape[1], np.bool)\n",
    "    mask0[inds_0_col] = 0\n",
    "    Y_filt_col = Y_filt[:,mask0]\n",
    "    Y_filt_col.shape\n",
    "    \n",
    "    inds_0 = np.where((Y_filt_col == 0).all(axis=1))[0] # Indices of rows fully equals 0\n",
    "    mask = np.ones(len(Y_filt_col), np.bool)\n",
    "    mask[inds_0] = 0\n",
    "    Y_filt_rows = Y_filt_col[mask,:]\n",
    "    \n",
    "    vocabs_filt = vocabs[mask]\n",
    "    X_filt = X[mask]\n",
    "    Y_filt = Y_filt_rows\n",
    "    \n",
    "    return X_filt, Y_filt, vocabs_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filt, Y_filt, vocabs_filt = remove_low_frequencies(X,Y_mlb, vocabs, seuil = 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424,) (424, 15) (424,)\n"
     ]
    }
   ],
   "source": [
    "print(X_filt.shape, Y_filt.shape, vocabs_filt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= RF =======\n",
      "[Errno 12] Cannot allocate memory\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.52      0.44        31\n",
      "           1       0.27      0.28      0.27        36\n",
      "           2       0.20      0.29      0.24        28\n",
      "           3       0.47      0.60      0.53        40\n",
      "           4       0.41      0.42      0.42        33\n",
      "           5       0.48      0.46      0.47        28\n",
      "           6       0.26      0.30      0.28        47\n",
      "           7       0.43      0.40      0.42        50\n",
      "           8       0.30      0.36      0.33        28\n",
      "           9       0.33      0.32      0.33        31\n",
      "          10       0.21      0.22      0.22        27\n",
      "          11       0.21      0.30      0.25        33\n",
      "          12       0.17      0.21      0.19        33\n",
      "          13       0.18      0.22      0.20        36\n",
      "          14       0.19      0.28      0.23        25\n",
      "\n",
      "   micro avg       0.30      0.35      0.32       506\n",
      "   macro avg       0.30      0.35      0.32       506\n",
      "weighted avg       0.31      0.35      0.33       506\n",
      " samples avg       0.28      0.37      0.30       506\n",
      "\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.60      0.08      0.15        36\n",
      "           2       0.46      0.21      0.29        28\n",
      "           3       0.33      0.03      0.05        40\n",
      "           4       0.75      0.09      0.16        33\n",
      "           5       0.56      0.18      0.27        28\n",
      "           6       0.50      0.06      0.11        47\n",
      "           7       0.50      0.06      0.11        50\n",
      "           8       1.00      0.04      0.07        28\n",
      "           9       1.00      0.03      0.06        31\n",
      "          10       0.25      0.04      0.06        27\n",
      "          11       0.00      0.00      0.00        33\n",
      "          12       0.50      0.03      0.06        33\n",
      "          13       1.00      0.11      0.20        36\n",
      "          14       0.50      0.04      0.07        25\n",
      "\n",
      "   micro avg       0.52      0.07      0.12       506\n",
      "   macro avg       0.53      0.07      0.11       506\n",
      "weighted avg       0.53      0.07      0.11       506\n",
      " samples avg       0.07      0.06      0.06       506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# With only the most frequent tags\n",
    "run_classifiers(clfs, X_filt, Y_filt, pipeline1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= RF =======\n",
      "[Errno 12] Cannot allocate memory\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.26      0.25        31\n",
      "           1       0.31      0.31      0.31        13\n",
      "           2       0.47      0.64      0.55        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.25      0.17      0.20        36\n",
      "           5       0.15      0.22      0.18         9\n",
      "           6       0.31      0.29      0.30        28\n",
      "           7       0.12      0.12      0.12        16\n",
      "           8       0.55      0.43      0.48        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.83      0.91         6\n",
      "          11       0.10      0.11      0.10        19\n",
      "          12       0.40      0.47      0.44        40\n",
      "          13       0.50      0.47      0.49        19\n",
      "          14       0.19      0.24      0.21        17\n",
      "          15       0.43      0.38      0.40         8\n",
      "          16       0.50      0.17      0.25         6\n",
      "          17       0.34      0.33      0.34        33\n",
      "          18       0.47      0.50      0.48        28\n",
      "          19       0.17      0.19      0.18        47\n",
      "          20       0.43      0.48      0.45        50\n",
      "          21       0.33      0.25      0.29        16\n",
      "          22       0.12      0.20      0.15         5\n",
      "          23       0.58      0.64      0.61        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.48      0.46      0.47        28\n",
      "          26       0.17      0.12      0.14         8\n",
      "          27       0.26      0.23      0.24        31\n",
      "          28       0.13      0.11      0.12        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.44      0.33      0.38        12\n",
      "          31       0.20      0.20      0.20         5\n",
      "          32       0.62      0.56      0.59         9\n",
      "          33       0.16      0.21      0.18        33\n",
      "          34       0.13      0.15      0.14        33\n",
      "          35       0.19      0.25      0.21        36\n",
      "          36       0.71      0.67      0.69        15\n",
      "          37       0.44      0.37      0.40        19\n",
      "          38       0.80      0.67      0.73         6\n",
      "          39       0.40      0.36      0.38        11\n",
      "          40       0.27      0.32      0.29        25\n",
      "          41       0.17      0.17      0.17        12\n",
      "          42       0.44      0.36      0.40        11\n",
      "\n",
      "   micro avg       0.31      0.32      0.31       798\n",
      "   macro avg       0.33      0.31      0.31       798\n",
      "weighted avg       0.32      0.32      0.31       798\n",
      " samples avg       0.27      0.33      0.28       798\n",
      "\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.56      0.18      0.27        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.75      0.21      0.33        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      1.00      1.00         6\n",
      "          11       0.00      0.00      0.00        19\n",
      "          12       1.00      0.03      0.05        40\n",
      "          13       1.00      0.26      0.42        19\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.25      0.03      0.05        33\n",
      "          18       0.83      0.18      0.29        28\n",
      "          19       0.50      0.04      0.08        47\n",
      "          20       0.75      0.06      0.11        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       1.00      0.09      0.17        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.50      0.04      0.07        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       1.00      0.17      0.29        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       1.00      0.33      0.50         9\n",
      "          33       0.00      0.00      0.00        33\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.75      0.08      0.15        36\n",
      "          36       1.00      0.47      0.64        15\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       0.00      0.00      0.00         6\n",
      "          39       1.00      0.18      0.31        11\n",
      "          40       0.75      0.12      0.21        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.80      0.36      0.50        11\n",
      "\n",
      "   micro avg       0.63      0.07      0.13       798\n",
      "   macro avg       0.34      0.09      0.13       798\n",
      "weighted avg       0.39      0.07      0.11       798\n",
      " samples avg       0.08      0.08      0.08       798\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# all tags, WITH LEMMATIZER \n",
    "run_classifiers(clfs, X, Y_mlb, pipeline1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= RF =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       1.00      0.07      0.13        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.33      0.50         6\n",
      "          11       0.00      0.00      0.00        19\n",
      "          12       1.00      0.10      0.18        40\n",
      "          13       1.00      0.05      0.10        19\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.00      0.00      0.00        33\n",
      "          18       0.80      0.14      0.24        28\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.00      0.00      0.00        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       1.00      0.27      0.43        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       0.00      0.00      0.00         9\n",
      "          33       0.00      0.00      0.00        33\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.00      0.00      0.00        36\n",
      "          36       1.00      0.33      0.50        15\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       1.00      0.17      0.29         6\n",
      "          39       1.00      0.09      0.17        11\n",
      "          40       0.00      0.00      0.00        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       0.61      0.03      0.05       798\n",
      "   macro avg       0.20      0.04      0.06       798\n",
      "weighted avg       0.18      0.03      0.05       798\n",
      " samples avg       0.03      0.03      0.03       798\n",
      "\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.35      0.35        31\n",
      "           1       0.18      0.23      0.20        13\n",
      "           2       0.48      0.71      0.57        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.16      0.19      0.18        36\n",
      "           5       0.33      0.22      0.27         9\n",
      "           6       0.30      0.29      0.29        28\n",
      "           7       0.20      0.19      0.19        16\n",
      "           8       0.80      0.57      0.67        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.83      0.91         6\n",
      "          11       0.06      0.05      0.05        19\n",
      "          12       0.57      0.65      0.60        40\n",
      "          13       0.45      0.47      0.46        19\n",
      "          14       0.15      0.24      0.18        17\n",
      "          15       0.25      0.25      0.25         8\n",
      "          16       0.14      0.17      0.15         6\n",
      "          17       0.32      0.36      0.34        33\n",
      "          18       0.50      0.43      0.46        28\n",
      "          19       0.21      0.28      0.24        47\n",
      "          20       0.45      0.40      0.43        50\n",
      "          21       0.31      0.25      0.28        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.55      0.55      0.55        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.47      0.50      0.48        28\n",
      "          26       0.10      0.12      0.11         8\n",
      "          27       0.27      0.26      0.26        31\n",
      "          28       0.25      0.22      0.24        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.57      0.33      0.42        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       0.67      0.67      0.67         9\n",
      "          33       0.18      0.21      0.20        33\n",
      "          34       0.16      0.18      0.17        33\n",
      "          35       0.23      0.28      0.25        36\n",
      "          36       0.64      0.60      0.62        15\n",
      "          37       0.41      0.47      0.44        19\n",
      "          38       0.75      0.50      0.60         6\n",
      "          39       0.56      0.45      0.50        11\n",
      "          40       0.21      0.24      0.22        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.38      0.27      0.32        11\n",
      "\n",
      "   micro avg       0.32      0.33      0.32       798\n",
      "   macro avg       0.32      0.30      0.31       798\n",
      "weighted avg       0.33      0.33      0.33       798\n",
      " samples avg       0.28      0.35      0.30       798\n",
      "\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.50      0.07      0.12        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.50      0.07      0.12        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.83      0.36      0.50        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.83      0.91         6\n",
      "          11       0.00      0.00      0.00        19\n",
      "          12       0.33      0.03      0.05        40\n",
      "          13       0.83      0.26      0.40        19\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.40      0.06      0.11        33\n",
      "          18       1.00      0.21      0.35        28\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.67      0.04      0.08        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.33      0.09      0.14        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       1.00      0.04      0.07        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       1.00      0.17      0.29        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       1.00      0.33      0.50         9\n",
      "          33       0.60      0.18      0.28        33\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       1.00      0.06      0.11        36\n",
      "          36       1.00      0.40      0.57        15\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       0.00      0.00      0.00         6\n",
      "          39       1.00      0.18      0.31        11\n",
      "          40       1.00      0.08      0.15        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       1.00      0.27      0.43        11\n",
      "\n",
      "   micro avg       0.66      0.07      0.13       798\n",
      "   macro avg       0.35      0.09      0.13       798\n",
      "weighted avg       0.39      0.07      0.11       798\n",
      " samples avg       0.09      0.07      0.08       798\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing pipeline : No lemm\n",
    "pipeline_nolemm = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=100, random_state=1))])\n",
    "\n",
    "# WITHOUT LEMMATIZER\n",
    "run_classifiers(clfs, X, Y_mlb, pipeline_nolemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW TOKENIZER (J'ai essayÃ© en modifiant ngram_range=1 mais cela baisse le score f1 de 1%)\n",
    "pipeline2 = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=newTokenizer, min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=150, random_state=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= RF =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       1.00      0.14      0.25        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.50      0.67         6\n",
      "          11       0.00      0.00      0.00        19\n",
      "          12       1.00      0.10      0.18        40\n",
      "          13       0.00      0.00      0.00        19\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.00      0.00      0.00        33\n",
      "          18       1.00      0.14      0.25        28\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.33      0.02      0.04        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       1.00      0.36      0.53        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       1.00      0.04      0.07        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       0.00      0.00      0.00         9\n",
      "          33       0.00      0.00      0.00        33\n",
      "          34       0.50      0.03      0.06        33\n",
      "          35       0.00      0.00      0.00        36\n",
      "          36       1.00      0.47      0.64        15\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       1.00      0.17      0.29         6\n",
      "          39       0.00      0.00      0.00        11\n",
      "          40       0.00      0.00      0.00        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       0.70      0.04      0.07       798\n",
      "   macro avg       0.21      0.05      0.07       798\n",
      "weighted avg       0.23      0.04      0.06       798\n",
      " samples avg       0.04      0.04      0.04       798\n",
      "\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.45      0.41        31\n",
      "           1       0.33      0.31      0.32        13\n",
      "           2       0.56      0.36      0.43        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.24      0.28      0.26        36\n",
      "           5       0.40      0.22      0.29         9\n",
      "           6       0.23      0.29      0.25        28\n",
      "           7       0.11      0.12      0.11        16\n",
      "           8       0.56      0.64      0.60        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.83      0.91         6\n",
      "          11       0.33      0.16      0.21        19\n",
      "          12       0.48      0.50      0.49        40\n",
      "          13       0.56      0.47      0.51        19\n",
      "          14       0.18      0.24      0.21        17\n",
      "          15       0.43      0.38      0.40         8\n",
      "          16       0.50      0.17      0.25         6\n",
      "          17       0.40      0.36      0.38        33\n",
      "          18       0.52      0.46      0.49        28\n",
      "          19       0.24      0.23      0.24        47\n",
      "          20       0.44      0.46      0.45        50\n",
      "          21       0.36      0.31      0.33        16\n",
      "          22       0.25      0.20      0.22         5\n",
      "          23       0.86      0.55      0.67        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.52      0.46      0.49        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.35      0.26      0.30        31\n",
      "          28       0.11      0.07      0.09        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.42      0.42      0.42        12\n",
      "          31       0.40      0.40      0.40         5\n",
      "          32       0.62      0.56      0.59         9\n",
      "          33       0.22      0.24      0.23        33\n",
      "          34       0.15      0.18      0.16        33\n",
      "          35       0.25      0.28      0.26        36\n",
      "          36       0.64      0.60      0.62        15\n",
      "          37       0.40      0.42      0.41        19\n",
      "          38       0.75      0.50      0.60         6\n",
      "          39       0.71      0.45      0.56        11\n",
      "          40       0.21      0.24      0.23        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.44      0.36      0.40        11\n",
      "\n",
      "   micro avg       0.34      0.33      0.34       798\n",
      "   macro avg       0.36      0.31      0.33       798\n",
      "weighted avg       0.35      0.33      0.34       798\n",
      " samples avg       0.30      0.35      0.31       798\n",
      "\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       1.00      0.03      0.05        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.50      0.21      0.30        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       1.00      0.21      0.35        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.83      0.91         6\n",
      "          11       0.00      0.00      0.00        19\n",
      "          12       0.00      0.00      0.00        40\n",
      "          13       1.00      0.21      0.35        19\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.25      0.03      0.05        33\n",
      "          18       1.00      0.18      0.30        28\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.75      0.06      0.11        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.50      0.09      0.15        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       1.00      0.25      0.40        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       1.00      0.11      0.20         9\n",
      "          33       0.62      0.15      0.24        33\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.50      0.03      0.05        36\n",
      "          36       1.00      0.33      0.50        15\n",
      "          37       0.50      0.05      0.10        19\n",
      "          38       0.00      0.00      0.00         6\n",
      "          39       0.00      0.00      0.00        11\n",
      "          40       1.00      0.08      0.15        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.75      0.27      0.40        11\n",
      "\n",
      "   micro avg       0.65      0.06      0.11       798\n",
      "   macro avg       0.31      0.07      0.11       798\n",
      "weighted avg       0.36      0.06      0.10       798\n",
      " samples avg       0.07      0.06      0.07       798\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# New tokenizer (split maj words)\n",
    "run_classifiers(clfs, X, Y_mlb, pipeline2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= RF =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.50      0.07      0.12        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.33      0.50         6\n",
      "          11       0.00      0.00      0.00        19\n",
      "          12       0.83      0.12      0.22        40\n",
      "          13       1.00      0.05      0.10        19\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       1.00      0.12      0.22         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.00      0.00      0.00        33\n",
      "          18       1.00      0.18      0.30        28\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.33      0.02      0.04        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       1.00      0.36      0.53        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       1.00      0.07      0.13        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.50      0.03      0.06        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       0.00      0.00      0.00         9\n",
      "          33       0.00      0.00      0.00        33\n",
      "          34       0.67      0.06      0.11        33\n",
      "          35       0.00      0.00      0.00        36\n",
      "          36       1.00      0.40      0.57        15\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       1.00      0.17      0.29         6\n",
      "          39       0.00      0.00      0.00        11\n",
      "          40       0.50      0.04      0.07        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       1.00      0.09      0.17        11\n",
      "\n",
      "   micro avg       0.64      0.04      0.08       798\n",
      "   macro avg       0.29      0.05      0.08       798\n",
      "weighted avg       0.30      0.04      0.07       798\n",
      " samples avg       0.04      0.04      0.04       798\n",
      "\n",
      "\n",
      "\n",
      "======= BAGGING =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.10      0.15        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.50      0.07      0.12        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.14      0.03      0.05        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.20      0.07      0.11        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.77      0.71      0.74        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.83      0.91         6\n",
      "          11       0.20      0.05      0.08        19\n",
      "          12       0.50      0.17      0.26        40\n",
      "          13       0.50      0.16      0.24        19\n",
      "          14       0.09      0.06      0.07        17\n",
      "          15       0.50      0.12      0.20         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.00      0.00      0.00        33\n",
      "          18       0.43      0.32      0.37        28\n",
      "          19       0.19      0.06      0.10        47\n",
      "          20       0.38      0.10      0.16        50\n",
      "          21       0.50      0.12      0.20        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       1.00      0.36      0.53        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.71      0.18      0.29        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.36      0.13      0.19        31\n",
      "          28       0.50      0.04      0.07        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.67      0.17      0.27        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       0.00      0.00      0.00         9\n",
      "          33       0.20      0.06      0.09        33\n",
      "          34       0.31      0.12      0.17        33\n",
      "          35       0.40      0.06      0.10        36\n",
      "          36       0.85      0.73      0.79        15\n",
      "          37       0.57      0.21      0.31        19\n",
      "          38       0.29      0.33      0.31         6\n",
      "          39       0.67      0.18      0.29        11\n",
      "          40       0.25      0.04      0.07        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.50      0.18      0.27        11\n",
      "\n",
      "   micro avg       0.38      0.13      0.19       798\n",
      "   macro avg       0.31      0.13      0.17       798\n",
      "weighted avg       0.34      0.13      0.17       798\n",
      " samples avg       0.13      0.12      0.12       798\n",
      "\n",
      "\n",
      "\n",
      "======= ADABOOST =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.29      0.40        31\n",
      "           1       0.33      0.08      0.12        13\n",
      "           2       0.75      0.43      0.55        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.17      0.06      0.08        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.08      0.04      0.05        28\n",
      "           7       0.67      0.12      0.21        16\n",
      "           8       0.58      0.50      0.54        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.83      0.91         6\n",
      "          11       0.25      0.05      0.09        19\n",
      "          12       0.50      0.28      0.35        40\n",
      "          13       0.57      0.42      0.48        19\n",
      "          14       0.18      0.12      0.14        17\n",
      "          15       1.00      0.12      0.22         8\n",
      "          16       0.50      0.17      0.25         6\n",
      "          17       0.19      0.09      0.12        33\n",
      "          18       0.55      0.39      0.46        28\n",
      "          19       0.23      0.13      0.16        47\n",
      "          20       0.58      0.22      0.32        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       1.00      0.55      0.71        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.36      0.18      0.24        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.36      0.16      0.22        31\n",
      "          28       0.14      0.04      0.06        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.80      0.33      0.47        12\n",
      "          31       0.50      0.20      0.29         5\n",
      "          32       1.00      0.33      0.50         9\n",
      "          33       0.29      0.12      0.17        33\n",
      "          34       0.33      0.12      0.18        33\n",
      "          35       0.20      0.11      0.14        36\n",
      "          36       1.00      0.47      0.64        15\n",
      "          37       0.60      0.16      0.25        19\n",
      "          38       0.50      0.33      0.40         6\n",
      "          39       0.67      0.36      0.47        11\n",
      "          40       0.55      0.24      0.33        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.75      0.27      0.40        11\n",
      "\n",
      "   micro avg       0.43      0.19      0.26       798\n",
      "   macro avg       0.41      0.19      0.25       798\n",
      "weighted avg       0.40      0.19      0.25       798\n",
      " samples avg       0.20      0.20      0.20       798\n",
      "\n",
      "\n",
      "\n",
      "======= SVC =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.00      0.00      0.00        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       0.00      0.00      0.00         6\n",
      "          11       0.00      0.00      0.00        19\n",
      "          12       0.00      0.00      0.00        40\n",
      "          13       0.00      0.00      0.00        19\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.00      0.00      0.00        33\n",
      "          18       0.00      0.00      0.00        28\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.00      0.00      0.00        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.00      0.00      0.00        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       0.00      0.00      0.00         9\n",
      "          33       0.00      0.00      0.00        33\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.00      0.00      0.00        36\n",
      "          36       0.00      0.00      0.00        15\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       0.00      0.00      0.00         6\n",
      "          39       0.00      0.00      0.00        11\n",
      "          40       0.00      0.00      0.00        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       798\n",
      "   macro avg       0.00      0.00      0.00       798\n",
      "weighted avg       0.00      0.00      0.00       798\n",
      " samples avg       0.00      0.00      0.00       798\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# MULTILABEL with other classifiers with ONEVSREST\n",
    "clf_OvsR = {\n",
    "'RF': OneVsRestClassifier(RandomForestClassifier(n_estimators=100, random_state=1, n_jobs=-1)),\n",
    "'BAGGING': OneVsRestClassifier(BaggingClassifier(n_estimators=100,random_state=1)),\n",
    "'ADABOOST': OneVsRestClassifier(AdaBoostClassifier(n_estimators=100, random_state=1)),\n",
    "'SVC': OneVsRestClassifier(SVC(gamma='scale', decision_function_shape='ovo'))\n",
    "}\n",
    "\n",
    "run_classifiers(clf_OvsR, X, Y_mlb, pipeline2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= SVC =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.39      0.48        31\n",
      "           1       0.36      0.31      0.33        13\n",
      "           2       0.62      0.57      0.59        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.29      0.25      0.27        36\n",
      "           5       0.75      0.33      0.46         9\n",
      "           6       0.31      0.36      0.33        28\n",
      "           7       0.13      0.12      0.13        16\n",
      "           8       0.54      0.50      0.52        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      1.00      1.00         6\n",
      "          11       0.33      0.16      0.21        19\n",
      "          12       0.47      0.47      0.48        40\n",
      "          13       0.53      0.42      0.47        19\n",
      "          14       0.30      0.41      0.35        17\n",
      "          15       0.33      0.25      0.29         8\n",
      "          16       0.50      0.17      0.25         6\n",
      "          17       0.48      0.33      0.39        33\n",
      "          18       0.42      0.39      0.41        28\n",
      "          19       0.23      0.21      0.22        47\n",
      "          20       0.46      0.32      0.38        50\n",
      "          21       0.38      0.31      0.34        16\n",
      "          22       0.50      0.40      0.44         5\n",
      "          23       0.88      0.64      0.74        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.48      0.39      0.43        28\n",
      "          26       0.14      0.12      0.13         8\n",
      "          27       0.48      0.32      0.38        31\n",
      "          28       0.13      0.07      0.10        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.60      0.50      0.55        12\n",
      "          31       0.50      0.40      0.44         5\n",
      "          32       0.67      0.44      0.53         9\n",
      "          33       0.35      0.42      0.38        33\n",
      "          34       0.12      0.15      0.14        33\n",
      "          35       0.39      0.25      0.31        36\n",
      "          36       0.75      0.60      0.67        15\n",
      "          37       0.28      0.26      0.27        19\n",
      "          38       0.75      0.50      0.60         6\n",
      "          39       0.50      0.36      0.42        11\n",
      "          40       0.35      0.28      0.31        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.57      0.36      0.44        11\n",
      "\n",
      "   micro avg       0.39      0.32      0.36       798\n",
      "   macro avg       0.41      0.32      0.35       798\n",
      "weighted avg       0.40      0.32      0.35       798\n",
      " samples avg       0.31      0.34      0.32       798\n",
      "\n",
      "\n",
      "\n",
      "======= SVC_poly =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.16      0.26        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.67      0.29      0.40        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.21      0.11      0.14        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.56      0.36      0.43        14\n",
      "           9       0.02      0.40      0.03         5\n",
      "          10       1.00      0.67      0.80         6\n",
      "          11       0.17      0.05      0.08        19\n",
      "          12       0.64      0.23      0.33        40\n",
      "          13       0.57      0.21      0.31        19\n",
      "          14       0.24      0.24      0.24        17\n",
      "          15       0.33      0.25      0.29         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.27      0.09      0.14        33\n",
      "          18       0.46      0.21      0.29        28\n",
      "          19       0.15      0.04      0.07        47\n",
      "          20       0.43      0.12      0.19        50\n",
      "          21       0.29      0.12      0.17        16\n",
      "          22       1.00      0.20      0.33         5\n",
      "          23       0.70      0.64      0.67        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.42      0.18      0.25        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.60      0.10      0.17        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.50      0.20      0.29         5\n",
      "          32       0.25      0.11      0.15         9\n",
      "          33       0.50      0.06      0.11        33\n",
      "          34       0.27      0.12      0.17        33\n",
      "          35       0.62      0.14      0.23        36\n",
      "          36       1.00      0.53      0.70        15\n",
      "          37       0.40      0.11      0.17        19\n",
      "          38       0.67      0.33      0.44         6\n",
      "          39       0.67      0.36      0.47        11\n",
      "          40       0.36      0.16      0.22        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.40      0.18      0.25        11\n",
      "\n",
      "   micro avg       0.28      0.14      0.19       798\n",
      "   macro avg       0.35      0.16      0.20       798\n",
      "weighted avg       0.37      0.14      0.19       798\n",
      " samples avg       0.12      0.14      0.12       798\n",
      "\n",
      "\n",
      "\n",
      "======= SVC_lin =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.52      0.52        31\n",
      "           1       0.24      0.31      0.27        13\n",
      "           2       0.57      0.57      0.57        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.25      0.39      0.30        36\n",
      "           5       0.38      0.33      0.35         9\n",
      "           6       0.27      0.46      0.34        28\n",
      "           7       0.10      0.19      0.13        16\n",
      "           8       0.56      0.64      0.60        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      1.00      1.00         6\n",
      "          11       0.22      0.21      0.22        19\n",
      "          12       0.35      0.57      0.43        40\n",
      "          13       0.55      0.58      0.56        19\n",
      "          14       0.27      0.47      0.34        17\n",
      "          15       0.27      0.38      0.32         8\n",
      "          16       0.17      0.17      0.17         6\n",
      "          17       0.33      0.45      0.38        33\n",
      "          18       0.42      0.54      0.47        28\n",
      "          19       0.19      0.36      0.25        47\n",
      "          20       0.38      0.46      0.41        50\n",
      "          21       0.31      0.31      0.31        16\n",
      "          22       0.50      0.40      0.44         5\n",
      "          23       0.47      0.64      0.54        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.27      0.46      0.34        28\n",
      "          26       0.12      0.12      0.12         8\n",
      "          27       0.28      0.32      0.30        31\n",
      "          28       0.19      0.26      0.22        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.45      0.42      0.43        12\n",
      "          31       0.38      0.60      0.46         5\n",
      "          32       0.36      0.56      0.43         9\n",
      "          33       0.30      0.48      0.37        33\n",
      "          34       0.12      0.27      0.16        33\n",
      "          35       0.17      0.28      0.21        36\n",
      "          36       0.77      0.67      0.71        15\n",
      "          37       0.35      0.42      0.38        19\n",
      "          38       0.75      0.50      0.60         6\n",
      "          39       0.25      0.36      0.30        11\n",
      "          40       0.12      0.28      0.17        25\n",
      "          41       0.12      0.17      0.14        12\n",
      "          42       0.38      0.27      0.32        11\n",
      "\n",
      "   micro avg       0.29      0.41      0.34       798\n",
      "   macro avg       0.32      0.38      0.34       798\n",
      "weighted avg       0.31      0.41      0.35       798\n",
      " samples avg       0.28      0.42      0.32       798\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# MULTILABEL with other classifiers with ONEVSREST and weight classes\n",
    "clf_OvsR_cb = {\n",
    "'SVC': OneVsRestClassifier(SVC(C=10, gamma=1, kernel=\"rbf\", decision_function_shape='ovo',class_weight=\"balanced\")),\n",
    "'SVC_poly': OneVsRestClassifier(SVC(C=10, gamma=1, kernel=\"poly\", degree=5, decision_function_shape='ovo',class_weight=\"balanced\")),\n",
    "'SVC_lin': OneVsRestClassifier(SVC(C=10, gamma=1, kernel=\"linear\", decision_function_shape='ovo',class_weight=\"balanced\"))\n",
    "}\n",
    "\n",
    "run_classifiers(clf_OvsR_cb, X, Y_mlb, pipeline2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KERAS MLP with class balanced ###\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will set the model for calling it with the Scikit learn API\n",
    "\n",
    "np.random.seed(1)\n",
    "epochs = 2\n",
    "batch_size = 10\n",
    "\n",
    "def create_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=input_dim))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Final layer\n",
    "    model.add(Dense(len(Y_mlb[0])))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weights\n",
    "class_weights = np.apply_along_axis(np.count_nonzero, 0, Y_mlb)\n",
    "\n",
    "# MLP (keras) model inside sklearn container : it seems that it doesnt work for multilabel\n",
    "modelSL = KerasClassifier(build_fn=create_model, epochs=epochs, input_dim=150,\n",
    "                          batch_size=batch_size, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(input_dim=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_proc = pipeline2.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_proc, Y_mlb, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 524 samples, validate on 132 samples\n",
      "Epoch 1/2\n",
      "524/524 [==============================] - 3s 5ms/step - loss: 0.6795 - acc: 0.6835 - val_loss: 0.6602 - val_acc: 0.9003\n",
      "Epoch 2/2\n",
      "524/524 [==============================] - 0s 84us/step - loss: 0.6390 - acc: 0.9379 - val_loss: 0.6131 - val_acc: 0.9686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd58b157d68>"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds_int = np.zeros_like(ypreds)\n",
    "ypreds_int[ypreds>=0.5] = 1\n",
    "ypreds_int[ypreds<0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4622172 , 0.45595413, 0.4451928 , ..., 0.48109657, 0.44433624,\n",
       "        0.45964527],\n",
       "       [0.44989595, 0.44656977, 0.43128407, ..., 0.47243938, 0.44211453,\n",
       "        0.43749115],\n",
       "       [0.45616174, 0.45809048, 0.43857908, ..., 0.45111233, 0.4384106 ,\n",
       "        0.46056068],\n",
       "       ...,\n",
       "       [0.46897402, 0.48087987, 0.4401327 , ..., 0.48095387, 0.45686913,\n",
       "        0.4417004 ],\n",
       "       [0.46077904, 0.48773313, 0.4485871 , ..., 0.48432496, 0.4525258 ,\n",
       "        0.4796526 ],\n",
       "       [0.46500972, 0.4602896 , 0.45285636, ..., 0.4594692 , 0.4609194 ,\n",
       "        0.4537854 ]], dtype=float32)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 22,  38,  46,  79,  82,  82,  91, 110, 112, 121]),\n",
       " array([23, 34, 34,  7,  0, 25,  7,  7, 23, 28]))"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(ypreds_int == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, ypreds_int, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 4.5621 - acc: 0.0496\n",
      "Epoch 2/5\n",
      "524/524 [==============================] - 0s 149us/step - loss: 4.4983 - acc: 0.1088\n",
      "Epoch 3/5\n",
      "524/524 [==============================] - 0s 157us/step - loss: 4.3979 - acc: 0.1183\n",
      "Epoch 4/5\n",
      "524/524 [==============================] - 0s 157us/step - loss: 4.2570 - acc: 0.1126\n",
      "Epoch 5/5\n",
      "524/524 [==============================] - 0s 149us/step - loss: 4.1328 - acc: 0.1069\n",
      "132/132 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 4.5765 - acc: 0.0533\n",
      "Epoch 2/5\n",
      "525/525 [==============================] - 0s 152us/step - loss: 4.5080 - acc: 0.0914\n",
      "Epoch 3/5\n",
      "525/525 [==============================] - 0s 146us/step - loss: 4.3978 - acc: 0.1276\n",
      "Epoch 4/5\n",
      "525/525 [==============================] - 0s 154us/step - loss: 4.2496 - acc: 0.0952\n",
      "Epoch 5/5\n",
      "525/525 [==============================] - 0s 146us/step - loss: 4.1253 - acc: 0.1124\n",
      "131/131 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 4.5833 - acc: 0.0514\n",
      "Epoch 2/5\n",
      "525/525 [==============================] - 0s 143us/step - loss: 4.5256 - acc: 0.1124\n",
      "Epoch 3/5\n",
      "525/525 [==============================] - 0s 148us/step - loss: 4.4289 - acc: 0.1333\n",
      "Epoch 4/5\n",
      "525/525 [==============================] - 0s 145us/step - loss: 4.2962 - acc: 0.1086\n",
      "Epoch 5/5\n",
      "525/525 [==============================] - 0s 145us/step - loss: 4.1724 - acc: 0.1124\n",
      "131/131 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 4.4829 - acc: 0.0400\n",
      "Epoch 2/5\n",
      "525/525 [==============================] - 0s 148us/step - loss: 4.4214 - acc: 0.1048\n",
      "Epoch 3/5\n",
      "525/525 [==============================] - 0s 165us/step - loss: 4.3190 - acc: 0.1276\n",
      "Epoch 4/5\n",
      "525/525 [==============================] - 0s 154us/step - loss: 4.1787 - acc: 0.1257\n",
      "Epoch 5/5\n",
      "525/525 [==============================] - 0s 145us/step - loss: 4.0498 - acc: 0.1124\n",
      "131/131 [==============================] - 0s 3ms/step\n",
      "Epoch 1/5\n",
      "525/525 [==============================] - 1s 2ms/step - loss: 4.5920 - acc: 0.0457\n",
      "Epoch 2/5\n",
      "525/525 [==============================] - 0s 150us/step - loss: 4.5301 - acc: 0.0971\n",
      "Epoch 3/5\n",
      "525/525 [==============================] - 0s 141us/step - loss: 4.4311 - acc: 0.1638\n",
      "Epoch 4/5\n",
      "525/525 [==============================] - 0s 147us/step - loss: 4.2873 - acc: 0.1524\n",
      "Epoch 5/5\n",
      "525/525 [==============================] - 0s 144us/step - loss: 4.1640 - acc: 0.1124\n",
      "131/131 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "y_pred = cross_val_predict(modelSL, X_proc, Y_mlb, cv=kf)\n",
    "#print(classification_report(Y_mlb, y_pred))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 19, 20, 20, 19, 19, 19, 20, 20, 20, 20, 20, 19, 20, 20, 19, 20,\n",
       "       19, 20, 20, 19, 19, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "       19, 20, 19, 19, 19, 19, 20, 20, 19, 19, 20, 20, 19, 20, 19, 20, 20,\n",
       "       19, 20, 19, 20, 19, 20, 19, 19, 20, 20, 20, 19, 20, 20, 20, 19, 20,\n",
       "       19, 20, 19, 19, 19, 20, 19, 19, 19, 20, 19, 20, 19, 20, 19, 20, 20,\n",
       "       19, 19, 20, 20, 19, 19, 20, 19, 20, 20, 20, 20, 19, 20, 19, 20, 20,\n",
       "       20, 19, 12, 19, 20, 19, 19, 19, 19, 20, 19, 19, 20, 20, 20, 20, 19,\n",
       "       20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 19, 20,\n",
       "       19, 19, 20, 20, 20, 19, 20, 20, 20, 19, 20, 19, 20, 19, 19, 19, 20,\n",
       "       20, 19, 19, 20, 20, 20, 20, 19, 19, 20, 19, 19, 19, 20, 19, 20, 19,\n",
       "       19, 19, 19, 19, 20, 20, 20, 19, 19, 20, 20, 20, 20, 20, 19, 20, 20,\n",
       "       19, 19, 20, 19, 19, 20, 20, 20, 19, 19, 19, 20, 20, 20, 19, 19, 19,\n",
       "       20, 19, 19, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 19, 20,\n",
       "       20, 19, 20, 19, 19, 19, 20, 20, 20, 19, 19, 20, 19, 20, 19, 19, 19,\n",
       "       19, 12, 19, 20, 20, 12, 20, 19, 19, 20, 19, 20, 20, 19, 19, 20, 20,\n",
       "       20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 19, 20, 19,\n",
       "       19, 20, 20, 19, 12, 20, 19, 20, 20, 20, 12, 20, 20, 19, 19, 20, 20,\n",
       "       20, 20, 19, 20, 19, 20, 20, 19, 20, 19, 19, 20, 19, 20, 19, 19, 20,\n",
       "       19, 20, 19, 20, 20, 20, 19, 19, 20, 19, 20, 19, 19, 19, 20, 20, 20,\n",
       "       20, 20, 19, 20, 19, 19, 19, 19, 20, 19, 19, 19, 19, 19, 19, 19, 20,\n",
       "       20, 20, 19, 20, 19, 19, 19, 20, 19, 20, 20, 20, 19, 20, 20, 19, 20,\n",
       "       20, 20, 20, 19, 19, 19, 19, 20, 19, 19, 19, 19, 19, 20, 19, 20, 19,\n",
       "       20, 20, 12, 20, 20, 20, 19, 19, 20, 20, 19, 20, 20, 20, 19, 20, 20,\n",
       "       20, 19, 20, 20, 12, 20, 19, 19, 12, 20, 19, 19, 19, 20, 19, 20, 20,\n",
       "       20, 19, 19, 19, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 19, 20,\n",
       "       20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 19, 19, 20, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 19, 20, 19, 20, 19, 19, 19, 20, 20, 20, 20, 20, 19,\n",
       "       19, 20, 19, 19, 19, 20, 19, 20, 20, 19, 20, 19, 19, 20, 20, 20, 20,\n",
       "       19, 19, 19, 19, 20, 19, 19, 20, 19, 20, 20, 20, 20, 19, 20, 12, 20,\n",
       "       19, 20, 19, 19, 20, 20, 19, 19, 20, 19, 20, 20, 19, 20, 20, 19, 20,\n",
       "       19, 19, 20, 20, 20, 19, 19, 20, 19, 19, 19, 19, 20, 20, 20, 20, 19,\n",
       "       20, 20, 19, 20, 19, 19, 20, 19, 19, 19, 20, 19, 19, 19, 19, 20, 19,\n",
       "       20, 20, 20, 19, 19, 19, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 19,\n",
       "       20, 20, 20, 20, 20, 20, 19, 19, 19, 20, 19, 12, 20, 19, 19, 20, 20,\n",
       "       20, 20, 20, 20, 20, 12, 20, 19, 19, 20, 19, 20, 20, 20, 20, 20, 19,\n",
       "       19, 20, 19, 19, 20, 19, 20, 19, 20, 20, 20, 19, 20, 20, 20, 19, 20,\n",
       "       19, 19, 20, 20, 20, 19, 20, 19, 19, 20, 19, 20, 20, 20, 19, 20, 20,\n",
       "       20, 20, 19, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20,\n",
       "       20, 19, 20, 20, 19, 20, 20, 20, 19, 20])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEST MLP PIPELINE\n",
    "pipeline_mlp = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=100, random_state=1)),\n",
    "            ('MLP', MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(100),random_state=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, vocabs_train, vocabs_test = train_test_split(X, Y_mlb, vocabs, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.25, max_features=None, min_df=0.0025,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf...True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False))])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "pipeline_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probas = pipeline_mlp.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.61084114e-26, 3.03420474e-28, 1.97892467e-38, ...,\n",
       "        6.45401528e-29, 4.43539277e-38, 1.25558894e-34],\n",
       "       [1.35484764e-13, 1.18487097e-56, 1.98329224e-41, ...,\n",
       "        6.35343769e-11, 4.07530161e-10, 1.88383652e-52],\n",
       "       [1.76924771e-25, 3.42626342e-34, 1.11219954e-49, ...,\n",
       "        2.56725686e-34, 4.22418826e-47, 2.40280405e-37],\n",
       "       ...,\n",
       "       [6.53904933e-52, 8.00590038e-31, 3.38471659e-37, ...,\n",
       "        9.24587112e-28, 2.09201948e-39, 1.20330368e-46],\n",
       "       [3.95278898e-84, 3.23055830e-38, 6.55220352e-72, ...,\n",
       "        1.77668911e-33, 4.14978945e-97, 1.34202954e-86],\n",
       "       [1.16159507e-26, 5.16314801e-25, 2.24881456e-53, ...,\n",
       "        2.80328582e-30, 7.04062310e-55, 2.66813690e-27]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one tag for each prediction by the highest value in the predicted vector\n",
    "row_maxs = y_pred_probas.max(axis=1, keepdims=True)\n",
    "# Indices of maximum value for each row\n",
    "y_pred1 = np.where(y_pred_probas == row_maxs, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Society',), ('RDF',), ('Services',), ('Environment',), ('Services',)]\n",
      "[('API',), ('RDF',), ('Security',), ('Time',), ('Society',)]\n",
      "['wdrs' 'rr' 'algo' 'interval' 'comm']\n"
     ]
    }
   ],
   "source": [
    "# Compare prediction and true label\n",
    "print(mlb.inverse_transform(y_pred1[:5]))\n",
    "print(mlb.inverse_transform(y_test[:5]))\n",
    "print(vocabs_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.54885587e-120 4.02558368e-033 4.97503419e-049 5.88969552e-042\n",
      " 1.53312744e-071 2.28532802e-127 1.70999415e-094 1.06012728e-075\n",
      " 5.04039157e-063 1.63265017e-037 4.36245761e-098 7.02502911e-054\n",
      " 7.30329951e-092 3.08354532e-057 6.37495054e-116 2.31459374e-062\n",
      " 1.27203227e-082 3.03122087e-105 1.59619395e-086 3.35553572e-066\n",
      " 9.99999999e-001 4.90648356e-077 1.08729097e-073 5.49531645e-032\n",
      " 9.07680576e-053 1.21609655e-106 4.90804301e-051 3.36449920e-006\n",
      " 1.10067037e-060 3.58686655e-046 1.89011519e-028 3.55901399e-145\n",
      " 1.06019624e-102 1.47854944e-059 7.19587903e-098 2.99722375e-014\n",
      " 5.51782322e-062 8.25005058e-058 3.03752267e-067 2.98471665e-086\n",
      " 6.40590116e-045 1.28706158e-083 2.42568169e-047]\n",
      "(array([20]),)\n"
     ]
    }
   ],
   "source": [
    "# It seems that labels are predicted if value of neuron > 0.5\n",
    "print(y_pred_probas[4])\n",
    "print(np.where(y_pred[4] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26459143968871596\n",
      "0.35051546391752575\n",
      "0.25569895221058014\n",
      "0.2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "print(precision_score(y_test, y_pred, average=\"micro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_metric(y_true, y_pred_proba):\n",
    "    # Keep only one label with the higher proba\n",
    "    row_maxs = y_pred_proba.max(axis=1, keepdims=True)\n",
    "    # Indices of maximum value for each row\n",
    "    maxis = np.where(y_pred_proba == row_maxs, 1, 0)\n",
    "    # 1 if max value is indeed a tag, 0 otherwise\n",
    "    check = y_true[maxis == 1]\n",
    "    return np.mean(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35365853658536583\n"
     ]
    }
   ],
   "source": [
    "print(cust_metric(y_test, y_pred_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "########### TRAIN MODEL WITH ALL DATA ###########\n",
    "#################################################\n",
    "\n",
    "pipeline_mlp = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=100, random_state=1)),\n",
    "            ('MLP', MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(100),random_state=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.25, max_features=None, min_df=0.0025,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf...True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_mlp.fit(X, Y_mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_mlp.predict([\"events all the events i love\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlb.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save pipeline and mlb transformer\n",
    "joblib.dump(pipeline_mlp, \"clf.pkl\")\n",
    "\n",
    "joblib.dump(mlb, \"mlb.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9906542056074766\n",
      "0.9875776397515528\n",
      "0.8772609819121449\n",
      "0.99375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Prediction on train set\n",
    "y_pred = pipeline_mlp.predict(X_test)\n",
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "print(precision_score(y_test, y_pred, average=\"micro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_pred[:4])\n",
    "#print(y_test[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load new LoV vocabs\n",
    "with open('newDATA.pkl', 'rb') as handle:\n",
    "    Xnew, vocabs = pickle.load(handle)\n",
    "    \n",
    "Xnew = np.array(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew_pred = pipeline_mlp.predict(Xnew)\n",
    "ynew_predProba = pipeline_mlp.predict_proba(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one tag for each prediction by the highest value in the predicted vector\n",
    "row_maxs = ynew_predProba.max(axis=1, keepdims=True)\n",
    "# Indices of maximum value for each row\n",
    "ynew_pred1 = np.where(ynew_predProba == row_maxs, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UsabilityOntology.rdf', 'cultural-event.owl', 'munc.owl', 'catalogue.owl', 'terms.ttl', 'denotative-description.owl', 'context-description.owl', 'ontology.ttl', 'location.owl', 'core.owl', 'vir.ttl', 'arco.owl']\n"
     ]
    }
   ],
   "source": [
    "print(vocabs)\n",
    "newPreds = mlb.inverse_transform(ynew_pred)\n",
    "newPreds1 = mlb.inverse_transform(ynew_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('UsabilityOntology.rdf', (), ('API',)),\n",
       " ('cultural-event.owl', ('Events', 'Multimedia'), ('Events',)),\n",
       " ('munc.owl', ('RDF',), ('RDF',)),\n",
       " ('catalogue.owl', ('Catalogs', 'Government'), ('Government',)),\n",
       " ('terms.ttl', ('General & Upper', 'Services'), ('General & Upper',)),\n",
       " ('denotative-description.owl',\n",
       "  ('Catalogs', 'Events', 'Government'),\n",
       "  ('Catalogs',)),\n",
       " ('context-description.owl',\n",
       "  ('Catalogs', 'Events', 'Multimedia'),\n",
       "  ('Catalogs',)),\n",
       " ('ontology.ttl', ('Industry', 'Services'), ('Industry',)),\n",
       " ('location.owl', (), ('Events',)),\n",
       " ('core.owl', ('Events',), ('Events',)),\n",
       " ('vir.ttl', (), ('Support',)),\n",
       " ('arco.owl', ('Catalogs', 'Events', 'Multimedia'), ('Catalogs',))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x,y,z) for x,y,z in zip(vocabs, newPreds, newPreds1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST RANDOM FOREST\n",
    "pipeline_RF = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=100, random_state=1)),\n",
    "            ('RF', RandomForestClassifier(n_estimators=200, random_state=1, n_jobs=50))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.25, max_features=None, min_df=0.0025,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf...timators=200, n_jobs=50,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "pipeline_RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probas = pipeline_RF.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 43)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probas_proc = np.array(y_pred_probas)\n",
    "y_pred_probas_proc = y_pred_probas_proc[:,:,1].T\n",
    "y_pred_probas_proc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04 , 0.02 , 0.005, ..., 0.03 , 0.025, 0.   ],\n",
       "       [0.15 , 0.01 , 0.005, ..., 0.075, 0.065, 0.   ],\n",
       "       [0.02 , 0.005, 0.035, ..., 0.035, 0.015, 0.005],\n",
       "       ...,\n",
       "       [0.015, 0.01 , 0.015, ..., 0.055, 0.03 , 0.   ],\n",
       "       [0.02 , 0.005, 0.   , ..., 0.02 , 0.   , 0.005],\n",
       "       [0.04 , 0.06 , 0.015, ..., 0.015, 0.01 , 0.01 ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probas_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 43)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probas_proc.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(cust_metric(y_test, y_pred_probas_proc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "############## DOC2VEC approach #################\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "# Split (get explicit labels and no mlb)\n",
    "X_train, X_test, y_train, y_test, vocabs_train, vocabs_test = train_test_split(X, Y, vocabs, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged = [TaggedDocument(words = Tokenizer(doc), tags=tags) for doc, tags in zip(X_train, y_train)]\n",
    "test_tagged = [TaggedDocument(words = Tokenizer(doc), tags=tags) for doc, tags in zip(X_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 524/524 [00:00<00:00, 1213592.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Building vocab\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, window = 5,  negative=10, hs=0, min_count=2, sample = 0, workers=cores, seed=0)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 1s, sys: 625 ms, total: 3min 2s\n",
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dbow.train(train_tagged, total_examples=len(train_tagged), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text \n",
    "def doc_to_vec(X_tagged):\n",
    "    vect = [model_dbow.infer_vector(x[0]) for x in X_tagged]\n",
    "    return np.array(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = doc_to_vec(train_tagged)\n",
    "X_test_vect = doc_to_vec(test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524, 300)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mlb = mlb.transform(y_train)\n",
    "y_test_mlb = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train_mlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(200, 100),random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train_vect, y_train_mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test_vect)\n",
    "y_pred_proba = mlp.predict_proba(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29687499999999994"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_mlb, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3106060606060606"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_metric(y_test_mlb, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0, n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train_vect, y_train_mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test_vect)\n",
    "y_pred_proba = rf.predict_proba(X_test_vect)\n",
    "y_pred_probas_proc = np.array(y_pred_probas)\n",
    "y_pred_probas_proc = y_pred_probas_proc[:,:,1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03592814371257485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f1_score(y_test_mlb, y_pred, average=\"micro\"))\n",
    "cust_metric(y_test_mlb, y_pred_probas_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################## TEST WITH WORD EMBEDDING ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word embedding model\n",
    "with open(\"glove.6B.100d.txt\", \"rb\") as lines:\n",
    "    w2v = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "           for line in lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfemb = TfidfEmbeddingVectorizer(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-cf7d68cf7787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfidfemb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-197-d4b981b78227>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# known idf's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmax_idf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midf_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         self.word2weight = defaultdict(\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_idf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "tfidfemb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRID SEARCH\n",
    "\n",
    "classifier = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, min_df=.0025, max_df=0.25)),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', random_state=1)),\n",
    "            ('mlp', MLPClassifier(solver='lbfgs',hidden_layer_sizes=(100),random_state=1))\n",
    "            ])\n",
    "            \n",
    "params={'tfidf__ngram_range':[(1,3), (1,2)],\n",
    "        'svd__n_components':[60, 100, 150, 200, 300],\n",
    "        'mlp__solver':[\"lbfgs\", \"adam\"],\n",
    "        'mlp__hidden_layer_sizes':[(100), (200, 100), (100, 100)]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.25, max_features=None, min_df=0.0025,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf...True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'tfidf__ngram_range': [(1, 3), (1, 2)], 'svd__n_components': [60, 100, 150, 200, 300], 'mlp__solver': ['lbfgs', 'adam'], 'mlp__hidden_layer_sizes': [100, (200, 100), (100, 100)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(classifier, params, cv=4, scoring=\"f1_micro\")\n",
    "gs.fit(X,Y_mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2808492343646503"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
