{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, MaxPooling1D, Conv1D, Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam, rmsprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "# Function to plot results of a model\n",
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('DATA.pkl', 'rb') as handle:\n",
    "    X, Y, vocabs = pickle.load(handle)\n",
    "    \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform multilablels Y in sparse matrix for sklearn\n",
    "mlb = MultiLabelBinarizer(sparse_output=False)\n",
    "Y_mlb = mlb.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MAX_SEQUENCE_LENGTH = 2000\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Tokens 88397\n"
     ]
    }
   ],
   "source": [
    "# Tokenization keras : map chaque mot présent dans les textes à un nombre\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Number of Unique Tokens',len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nb de mots par documents\n",
    "len_X = [len(x) for x in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([465,  94,  34,  15,  14,   5,   3,   5,   7,   0,   0,   2,   1,\n",
       "          0,   2,   0,   0,   1,   2,   0,   1,   2,   0,   1,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   1,   0,   0,   0,   0,   0,   0,   1]),\n",
       " array([     0.  ,   1452.55,   2905.1 ,   4357.65,   5810.2 ,   7262.75,\n",
       "          8715.3 ,  10167.85,  11620.4 ,  13072.95,  14525.5 ,  15978.05,\n",
       "         17430.6 ,  18883.15,  20335.7 ,  21788.25,  23240.8 ,  24693.35,\n",
       "         26145.9 ,  27598.45,  29051.  ,  30503.55,  31956.1 ,  33408.65,\n",
       "         34861.2 ,  36313.75,  37766.3 ,  39218.85,  40671.4 ,  42123.95,\n",
       "         43576.5 ,  45029.05,  46481.6 ,  47934.15,  49386.7 ,  50839.25,\n",
       "         52291.8 ,  53744.35,  55196.9 ,  56649.45,  58102.  ,  59554.55,\n",
       "         61007.1 ,  62459.65,  63912.2 ,  65364.75,  66817.3 ,  68269.85,\n",
       "         69722.4 ,  71174.95,  72627.5 ,  74080.05,  75532.6 ,  76985.15,\n",
       "         78437.7 ,  79890.25,  81342.8 ,  82795.35,  84247.9 ,  85700.45,\n",
       "         87153.  ,  88605.55,  90058.1 ,  91510.65,  92963.2 ,  94415.75,\n",
       "         95868.3 ,  97320.85,  98773.4 , 100225.95, 101678.5 , 103131.05,\n",
       "        104583.6 , 106036.15, 107488.7 , 108941.25, 110393.8 , 111846.35,\n",
       "        113298.9 , 114751.45, 116204.  , 117656.55, 119109.1 , 120561.65,\n",
       "        122014.2 , 123466.75, 124919.3 , 126371.85, 127824.4 , 129276.95,\n",
       "        130729.5 , 132182.05, 133634.6 , 135087.15, 136539.7 , 137992.25,\n",
       "        139444.8 , 140897.35, 142349.9 , 143802.45, 145255.  ]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(len_X, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data Tensor: (656, 2000)\n"
     ]
    }
   ],
   "source": [
    "# On pad les documents pour qu'ils aient tous la même taille de MAX_SEQUENCE_LENGTH\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Shape of Data Tensor:', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(data, Y_mlb, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 400000 word vectors in Glove 6B 300d.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained GLOVE embeddings\n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.300d.txt',encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Total %s word vectors in Glove 6B 300d.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the embeddings with the words indexes and load an embedding layer\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified convolutional neural network\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 2000, 300)         26519400  \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1996, 128)         192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 399, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 395, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 79, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 75, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 43)                5547      \n",
      "=================================================================\n",
      "Total params: 26,914,067\n",
      "Trainable params: 26,914,067\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creation du modèle CNN\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(5)(l_cov2)\n",
    "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
    "l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
    "l_flat = Flatten()(l_pool3)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "preds = Dense(len(Y_mlb[0]), activation='sigmoid')(l_dense)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy', metrics=[\"accuracy\"],\n",
    "              optimizer=rmsprop())\n",
    "\n",
    "print(\"Simplified convolutional neural network\")\n",
    "model.summary()\n",
    "#cp=ModelCheckpoint('model_cnn.hdf5',monitor='val_acc',verbose=1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 492 samples, validate on 164 samples\n",
      "Epoch 1/10\n",
      "492/492 [==============================] - 51s 103ms/step - loss: 0.1515 - acc: 0.9632 - val_loss: 0.1363 - val_acc: 0.9711\n",
      "Epoch 2/10\n",
      "492/492 [==============================] - 50s 103ms/step - loss: 0.1311 - acc: 0.9719 - val_loss: 0.1360 - val_acc: 0.9711\n",
      "Epoch 3/10\n",
      "492/492 [==============================] - 51s 103ms/step - loss: 0.1262 - acc: 0.9719 - val_loss: 0.1444 - val_acc: 0.9711\n",
      "Epoch 4/10\n",
      "492/492 [==============================] - 51s 103ms/step - loss: 0.1230 - acc: 0.9719 - val_loss: 0.1321 - val_acc: 0.9711\n",
      "Epoch 5/10\n",
      "492/492 [==============================] - 52s 106ms/step - loss: 0.1169 - acc: 0.9719 - val_loss: 0.1291 - val_acc: 0.9711\n",
      "Epoch 6/10\n",
      "492/492 [==============================] - 51s 104ms/step - loss: 0.1094 - acc: 0.9721 - val_loss: 0.1301 - val_acc: 0.9709\n",
      "Epoch 7/10\n",
      "492/492 [==============================] - 51s 103ms/step - loss: 0.0995 - acc: 0.9731 - val_loss: 0.1375 - val_acc: 0.9706\n",
      "Epoch 8/10\n",
      "492/492 [==============================] - 51s 104ms/step - loss: 0.0875 - acc: 0.9739 - val_loss: 0.1336 - val_acc: 0.9687\n",
      "Epoch 9/10\n",
      "492/492 [==============================] - 51s 103ms/step - loss: 0.0766 - acc: 0.9763 - val_loss: 0.1357 - val_acc: 0.9691\n",
      "Epoch 10/10\n",
      "492/492 [==============================] - 51s 103ms/step - loss: 0.0656 - acc: 0.9792 - val_loss: 0.1585 - val_acc: 0.9644\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, validation_data=(X_valid, y_valid),epochs=10, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 1s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15852259717336514, 0.9644072462872761]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.63691354e-03, 1.58578157e-03, 1.57746673e-02, 7.53998756e-05,\n",
       "       3.38536799e-02, 6.94960356e-04, 2.18749046e-04, 6.31242990e-04,\n",
       "       1.31171942e-03, 2.92062759e-06, 1.31130219e-06, 1.04227662e-03,\n",
       "       4.23312187e-04, 4.76837158e-05, 4.83870506e-04, 1.71446800e-03,\n",
       "       4.94956970e-04, 4.29153442e-05, 3.60012054e-05, 7.90933669e-02,\n",
       "       5.21773100e-03, 2.02158093e-03, 1.21682882e-04, 1.29103661e-04,\n",
       "       5.96046448e-07, 1.31657720e-03, 5.12927771e-04, 1.59133703e-01,\n",
       "       1.23244226e-02, 1.60932541e-06, 1.34261787e-01, 1.25467777e-05,\n",
       "       7.68899918e-06, 1.01077557e-03, 8.18440318e-03, 5.25400043e-03,\n",
       "       4.07648087e-03, 1.48117542e-05, 2.98023224e-08, 4.02331352e-06,\n",
       "       1.04883015e-02, 1.74617171e-02, 5.02824783e-04], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_int = np.zeros_like(preds)\n",
    "preds_int[preds>=0.5] = 1\n",
    "preds_int[preds<0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059925093632958795"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_valid, preds_int, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_metric(y_true, y_pred):\n",
    "    row_maxs = y_pred.max(axis=1, keepdims=True)\n",
    "    maxis = np.where(y_pred == row_maxs, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09146341463414634"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_maxs = preds.max(axis=1, keepdims=True)\n",
    "maxis = np.where(preds == row_maxs, 1, 0)\n",
    "check = y_valid[maxis == 1]\n",
    "np.mean(check)\n",
    "#np.where(a == row_maxes).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01333001 0.00752717 0.01215923 0.00122723 0.02035478 0.0052467\n",
      " 0.03618518 0.0140928  0.00968164 0.00032535 0.00137419 0.02849156\n",
      " 0.07415041 0.02470866 0.01308507 0.00240651 0.00574085 0.03909755\n",
      " 0.01878512 0.04676759 0.09884825 0.00591114 0.00367641 0.00859213\n",
      " 0.00017795 0.04916164 0.00138214 0.03059036 0.01334745 0.00021717\n",
      " 0.01634333 0.0010317  0.00446758 0.02561405 0.04847297 0.02461442\n",
      " 0.00649095 0.01161435 0.00094911 0.00284097 0.03039992 0.01263708\n",
      " 0.00903228]\n",
      "[0.11438799 0.13647974 0.12322527 0.14172405 0.11731407 0.11743912\n",
      " 0.09884825 0.13318169 0.11369902 0.14408836 0.12593278 0.10090151\n",
      " 0.11628634 0.12908185 0.12012365 0.12707254 0.12643197 0.11636412\n",
      " 0.1157597  0.11926961 0.10910758 0.11495519 0.11769584 0.11668715\n",
      " 0.13547331 0.14047033 0.12012365 0.11812368 0.11942065 0.11653465\n",
      " 0.11468142 0.11641157 0.11286855 0.13846344 0.12726185 0.11819544\n",
      " 0.11703414 0.11418089 0.11628655 0.11277321 0.11781695 0.13115063\n",
      " 0.11593491 0.11848027 0.10343263 0.11087468 0.1158745  0.11957166\n",
      " 0.12012365 0.11835277 0.12012365 0.11832857 0.13492772 0.12005383\n",
      " 0.11672601 0.11972675 0.10795429 0.11601436 0.1113393  0.17366159\n",
      " 0.11660594 0.10771242 0.10459319 0.19813389 0.14640996 0.09422094\n",
      " 0.11732218 0.11445892 0.12487334 0.12012365 0.1189872  0.11559051\n",
      " 0.0908094  0.14898956 0.11730891 0.12012365 0.11688149 0.12012365\n",
      " 0.11389762 0.12133476 0.11704853 0.11538306 0.11554125 0.12012365\n",
      " 0.1155335  0.14458135 0.105838   0.11765799 0.11591813 0.11886221\n",
      " 0.11703277 0.11581182 0.143471   0.1327076  0.11315128 0.11701044\n",
      " 0.1138207  0.11596155 0.11117032 0.1414623  0.11536983 0.11359468\n",
      " 0.11753672 0.11697766 0.12012365 0.13411778 0.114308   0.11705923\n",
      " 0.1117985  0.11740002 0.11551979 0.11547327 0.13331217 0.11638591\n",
      " 0.09965217 0.12012365 0.11576676 0.10750663 0.1263549  0.10768491\n",
      " 0.10877576 0.12715527 0.12880635 0.11874548 0.11576942 0.11389434\n",
      " 0.11317444 0.13772863 0.11517438 0.12000877 0.12012365 0.11541125\n",
      " 0.11959514 0.1167866  0.11439127 0.09376284 0.11863035 0.14550555\n",
      " 0.12012365 0.13179472 0.11402836 0.12012365 0.11793813 0.1001021\n",
      " 0.11584789 0.10943127 0.11564869 0.1169669  0.13050446 0.11996853\n",
      " 0.12012365 0.11464325 0.11529082 0.11771592 0.12128657 0.11776018\n",
      " 0.11533871 0.11805511 0.13240722 0.13816857 0.13234904 0.12012365\n",
      " 0.13145226 0.11793125]\n"
     ]
    }
   ],
   "source": [
    "print(preds[6])\n",
    "#print(maxis[0])\n",
    "print(preds.max(axis=1, keepdims=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
