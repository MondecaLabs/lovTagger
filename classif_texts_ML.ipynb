{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mondeca/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate, cross_val_predict\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier    \n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, cohen_kappa_score, classification_report , precision_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('DATA.pkl', 'rb') as handle:\n",
    "    X, Y, vocabs = pickle.load(handle)\n",
    "    \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rooms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Floor Section. Contains. Desk. Building. Floor. A space inside a structure, typically separated from the outside by exterior walls and from other rooms in the same structure by internal walls. A human-made structure used for sheltering or continuous occupancy. Site. A simple vocabulary for describing the rooms in a building. An agent that generally occupies the physical area of the subject resource. Having this property implies being a spatial object. Being the object of this property implies being an agent. Intended for use with buildings, rooms, desks, etc. Room. The object resource is physically and spatially contained in the subject resource. Being the subject or object of this property implies being a spatial object. Intended for use in the context of buildings, rooms, etc. A table used in a work or office setting, typically for reading, writing, or computer use. A named part of a floor of a building. Typically used to denote several rooms that are grouped together based on spatial arrangement or use. A level part of a building that has a permanent roof. A storey of a building. . Occupant. An area of land with a designated purpose, such as a university Campus, a housing estate, or a building site. '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 490\n",
    "print(vocabs[n])\n",
    "X[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656 656 656\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(Y), len(vocabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study distribution of tags\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "totals = Counter(i for i in list(itertools.chain.from_iterable(Y)))\n",
    "distrib = dict(totals)\n",
    "#distrib = sorted(distrib.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags_len = np.sum(list(distrib.values()))\n",
    "distrib_freq = {key:val/all_tags_len for key,val in distrib.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedDistrib = sorted(distrib.items(), key = \n",
    "             lambda kv:(kv[1], kv[0]))\n",
    "np.sum([x[1] for x in sortedDistrib])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot distribution\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(10, 6), dpi= 80, facecolor='w', edgecolor='k')\n",
    "plt.bar([x[0] for x in sortedDistrib], [x[1] for x in sortedDistrib])\n",
    "plt.xticks(rotation='vertical', size = 10)\n",
    "for i in range(len(sortedDistrib)):\n",
    "    plt.text(x = i - 0.4 , y = sortedDistrib[i][1] + 0.5, s = sortedDistrib[i][1], size = 8)\n",
    "#plt.savefig('LOVTagsStat.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the number of uppercase in string\n",
    "def num_uppercase(string):\n",
    "    count = 0\n",
    "    for l in string:\n",
    "        if l.isupper():\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# From a list of words, split the words with more than one uppercase\n",
    "def split_uppercases(words):\n",
    "    words_proc = []\n",
    "    for word in words:\n",
    "        if num_uppercase(word) >= 1 and not(word.isupper()):\n",
    "            splitted_words = re.findall('[A-Za-z][a-z]*', word)\n",
    "            for w in splitted_words:\n",
    "                words_proc.append(w.lower())\n",
    "        else:\n",
    "            words_proc.append(word.lower())\n",
    "    return words_proc\n",
    "\n",
    "# Tokenizer\n",
    "def Tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    return words\n",
    "\n",
    "# Tokenizer : use stems of words\n",
    "def Tokenizer_lemm(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    porter_stemmer=nltk.PorterStemmer()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "# new Tokenizer : split the strings in the form \"jointAnnual\" with a space in the text\n",
    "def newTokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).split()\n",
    "    words = split_uppercases(words)\n",
    "    #porter_stemmer=nltk.PorterStemmer()\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    #words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('description', 'description'),\n",
       " ('knowledgegrouping', 'knowledge'),\n",
       " ('organization', 'grouping'),\n",
       " ('division', 'organization'),\n",
       " ('organizationalunit', 'division'),\n",
       " ('teaches', 'organizational'),\n",
       " ('institution', 'unit'),\n",
       " ('html', 'teaches'),\n",
       " ('subject', 'institution'),\n",
       " ('knowledgegrouping', 'html')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare both tokenizer\n",
    "[(x,y) for x,y in zip(Tokenizer(X[10]), newTokenizer(X[10]))][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.25, max_features=None, min_df=0.0025,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function newTokenizer at 0x7f4b8af60400>,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Study the CountVectorizer (WITHOUT NGRAMS)\n",
    "CV = CountVectorizer(tokenizer=newTokenizer, min_df=.0025, max_df=0.25, ngram_range=(1,1))\n",
    "CV.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21435\n"
     ]
    }
   ],
   "source": [
    "print(len(CV.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vect = CV.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(656, 21435)\n"
     ]
    }
   ],
   "source": [
    "print(X_vect.shape)\n",
    "X_vect_np = X_vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168.5121951219512\n",
      "0\n",
      "86208\n"
     ]
    }
   ],
   "source": [
    "# Mean of words per documents and min/max\n",
    "print(np.mean(np.sum(X_vect_np, axis=1)))\n",
    "print(np.min(np.sum(X_vect_np, axis=1)))\n",
    "print(np.max(np.sum(X_vect_np, axis=1)))\n",
    "#print(X_vect_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Number of documents of 0 words or < 20 words\n",
    "print(np.sum(np.sum(X_vect_np, axis=1) < 20))\n",
    "print(np.sum(np.sum(X_vect_np, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline : Vectorizer + tfidf + SVD\n",
    "pipeline1 = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer_lemm, min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=100, random_state=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of classifiers which work with multilabels\n",
    "clfs = {\n",
    "'RF': RandomForestClassifier(n_estimators=100, random_state=1, n_jobs=50),\n",
    "'MLP': MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(100),random_state=1),\n",
    "'KPPV': KNeighborsClassifier(n_neighbors=7)\n",
    "}\n",
    "\n",
    "# Test function of different classifiers\n",
    "def run_classifiers(clfs,X,Y, pipeline):\n",
    "    # Apply processing pipeline\n",
    "    X_proc = pipeline.fit_transform(X)\n",
    "    # Cross Validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    scoring = ['precision_macro', 'recall_macro', 'f1_macro', 'precision_micro', 'recall_micro']\n",
    "    for i in clfs:\n",
    "        try:\n",
    "            clf = clfs[i]\n",
    "            print(\"\\n\\n======= {0} =======\".format(i))\n",
    "            y_pred = cross_val_predict(clf, X_proc, Y, cv=kf)\n",
    "            print(classification_report(Y, y_pred))            \n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform multilablels Y in sparse matrix for sklearn\n",
    "mlb = MultiLabelBinarizer(sparse_output=False)\n",
    "Y_mlb = mlb.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the tags with a low frequency inferior of seuil\n",
    "# Some graphs will then not have any tags anymore, these graphs are the removed\n",
    "def remove_low_frequencies(X, Y_mlb, vocabs, seuil = 0.02):\n",
    "    labels_freqs = np.sum(Y_mlb, axis = 0) / np.sum(Y_mlb)\n",
    "    # Keeps only labels with freq > seuil\n",
    "    inds_col = labels_freqs > seuil\n",
    "    Y_filt = Y_mlb * inds_col\n",
    "    \n",
    "    inds_0_col = np.where((Y_filt == 0).all(axis=0))[0]\n",
    "    mask0 = np.ones(Y_filt.shape[1], np.bool)\n",
    "    mask0[inds_0_col] = 0\n",
    "    Y_filt_col = Y_filt[:,mask0]\n",
    "    Y_filt_col.shape\n",
    "    \n",
    "    inds_0 = np.where((Y_filt_col == 0).all(axis=1))[0] # Indices of rows fully equals 0\n",
    "    mask = np.ones(len(Y_filt_col), np.bool)\n",
    "    mask[inds_0] = 0\n",
    "    Y_filt_rows = Y_filt_col[mask,:]\n",
    "    \n",
    "    vocabs_filt = vocabs[mask]\n",
    "    X_filt = X[mask]\n",
    "    Y_filt = Y_filt_rows\n",
    "    \n",
    "    return X_filt, Y_filt, vocabs_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filt, Y_filt, vocabs_filt = remove_low_frequencies(X,Y_mlb, vocabs, seuil = 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424,) (424, 15) (424,)\n"
     ]
    }
   ],
   "source": [
    "print(X_filt.shape, Y_filt.shape, vocabs_filt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= RF =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        36\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       0.71      0.12      0.21        40\n",
      "           4       0.00      0.00      0.00        33\n",
      "           5       1.00      0.14      0.25        28\n",
      "           6       0.00      0.00      0.00        47\n",
      "           7       0.00      0.00      0.00        50\n",
      "           8       1.00      0.07      0.13        28\n",
      "           9       0.00      0.00      0.00        31\n",
      "          10       0.00      0.00      0.00        27\n",
      "          11       0.00      0.00      0.00        33\n",
      "          12       1.00      0.06      0.11        33\n",
      "          13       1.00      0.03      0.05        36\n",
      "          14       0.00      0.00      0.00        25\n",
      "\n",
      "   micro avg       0.70      0.03      0.05       506\n",
      "   macro avg       0.31      0.03      0.05       506\n",
      "weighted avg       0.30      0.03      0.05       506\n",
      " samples avg       0.02      0.02      0.02       506\n",
      "\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.52      0.44        31\n",
      "           1       0.27      0.28      0.27        36\n",
      "           2       0.20      0.29      0.24        28\n",
      "           3       0.47      0.60      0.53        40\n",
      "           4       0.41      0.42      0.42        33\n",
      "           5       0.48      0.46      0.47        28\n",
      "           6       0.26      0.30      0.28        47\n",
      "           7       0.43      0.40      0.42        50\n",
      "           8       0.30      0.36      0.33        28\n",
      "           9       0.33      0.32      0.33        31\n",
      "          10       0.21      0.22      0.22        27\n",
      "          11       0.21      0.30      0.25        33\n",
      "          12       0.17      0.21      0.19        33\n",
      "          13       0.18      0.22      0.20        36\n",
      "          14       0.19      0.28      0.23        25\n",
      "\n",
      "   micro avg       0.30      0.35      0.32       506\n",
      "   macro avg       0.30      0.35      0.32       506\n",
      "weighted avg       0.31      0.35      0.33       506\n",
      " samples avg       0.28      0.37      0.30       506\n",
      "\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.60      0.08      0.15        36\n",
      "           2       0.46      0.21      0.29        28\n",
      "           3       0.33      0.03      0.05        40\n",
      "           4       0.75      0.09      0.16        33\n",
      "           5       0.56      0.18      0.27        28\n",
      "           6       0.50      0.06      0.11        47\n",
      "           7       0.50      0.06      0.11        50\n",
      "           8       1.00      0.04      0.07        28\n",
      "           9       1.00      0.03      0.06        31\n",
      "          10       0.25      0.04      0.06        27\n",
      "          11       0.00      0.00      0.00        33\n",
      "          12       0.50      0.03      0.06        33\n",
      "          13       1.00      0.11      0.20        36\n",
      "          14       0.50      0.04      0.07        25\n",
      "\n",
      "   micro avg       0.52      0.07      0.12       506\n",
      "   macro avg       0.53      0.07      0.11       506\n",
      "weighted avg       0.53      0.07      0.11       506\n",
      " samples avg       0.07      0.06      0.06       506\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# With only the most frequent tags\n",
    "run_classifiers(clfs, X_filt, Y_filt, pipeline1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= RF =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.40      0.14      0.21        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.50      0.67         6\n",
      "          11       0.00      0.00      0.00        19\n",
      "          12       1.00      0.15      0.26        40\n",
      "          13       0.50      0.05      0.10        19\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       1.00      0.12      0.22         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.00      0.00      0.00        33\n",
      "          18       1.00      0.14      0.25        28\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.50      0.04      0.07        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       1.00      0.36      0.53        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       1.00      0.04      0.07        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       0.00      0.00      0.00         9\n",
      "          33       0.00      0.00      0.00        33\n",
      "          34       0.50      0.03      0.06        33\n",
      "          35       0.00      0.00      0.00        36\n",
      "          36       1.00      0.53      0.70        15\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       1.00      0.17      0.29         6\n",
      "          39       1.00      0.27      0.43        11\n",
      "          40       0.00      0.00      0.00        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       1.00      0.09      0.17        11\n",
      "\n",
      "   micro avg       0.70      0.05      0.09       798\n",
      "   macro avg       0.28      0.06      0.09       798\n",
      "weighted avg       0.28      0.05      0.08       798\n",
      " samples avg       0.05      0.05      0.05       798\n",
      "\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.26      0.25        31\n",
      "           1       0.31      0.31      0.31        13\n",
      "           2       0.47      0.64      0.55        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.25      0.17      0.20        36\n",
      "           5       0.15      0.22      0.18         9\n",
      "           6       0.31      0.29      0.30        28\n",
      "           7       0.12      0.12      0.12        16\n",
      "           8       0.55      0.43      0.48        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.83      0.91         6\n",
      "          11       0.10      0.11      0.10        19\n",
      "          12       0.40      0.47      0.44        40\n",
      "          13       0.50      0.47      0.49        19\n",
      "          14       0.19      0.24      0.21        17\n",
      "          15       0.43      0.38      0.40         8\n",
      "          16       0.50      0.17      0.25         6\n",
      "          17       0.34      0.33      0.34        33\n",
      "          18       0.47      0.50      0.48        28\n",
      "          19       0.17      0.19      0.18        47\n",
      "          20       0.43      0.48      0.45        50\n",
      "          21       0.33      0.25      0.29        16\n",
      "          22       0.12      0.20      0.15         5\n",
      "          23       0.58      0.64      0.61        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.48      0.46      0.47        28\n",
      "          26       0.17      0.12      0.14         8\n",
      "          27       0.26      0.23      0.24        31\n",
      "          28       0.13      0.11      0.12        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.44      0.33      0.38        12\n",
      "          31       0.20      0.20      0.20         5\n",
      "          32       0.62      0.56      0.59         9\n",
      "          33       0.16      0.21      0.18        33\n",
      "          34       0.13      0.15      0.14        33\n",
      "          35       0.19      0.25      0.21        36\n",
      "          36       0.71      0.67      0.69        15\n",
      "          37       0.44      0.37      0.40        19\n",
      "          38       0.80      0.67      0.73         6\n",
      "          39       0.40      0.36      0.38        11\n",
      "          40       0.27      0.32      0.29        25\n",
      "          41       0.17      0.17      0.17        12\n",
      "          42       0.44      0.36      0.40        11\n",
      "\n",
      "   micro avg       0.31      0.32      0.31       798\n",
      "   macro avg       0.33      0.31      0.31       798\n",
      "weighted avg       0.32      0.32      0.31       798\n",
      " samples avg       0.27      0.33      0.28       798\n",
      "\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.56      0.18      0.27        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.75      0.21      0.33        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      1.00      1.00         6\n",
      "          11       0.00      0.00      0.00        19\n",
      "          12       1.00      0.03      0.05        40\n",
      "          13       1.00      0.26      0.42        19\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.25      0.03      0.05        33\n",
      "          18       0.83      0.18      0.29        28\n",
      "          19       0.50      0.04      0.08        47\n",
      "          20       0.75      0.06      0.11        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       1.00      0.09      0.17        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.50      0.04      0.07        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       1.00      0.17      0.29        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       1.00      0.33      0.50         9\n",
      "          33       0.00      0.00      0.00        33\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.75      0.08      0.15        36\n",
      "          36       1.00      0.47      0.64        15\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       0.00      0.00      0.00         6\n",
      "          39       1.00      0.18      0.31        11\n",
      "          40       0.75      0.12      0.21        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.80      0.36      0.50        11\n",
      "\n",
      "   micro avg       0.63      0.07      0.13       798\n",
      "   macro avg       0.34      0.09      0.13       798\n",
      "weighted avg       0.39      0.07      0.11       798\n",
      " samples avg       0.08      0.08      0.08       798\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# all tags, WITH LEMMATIZER \n",
    "run_classifiers(clfs, X, Y_mlb, pipeline1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= RF =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       1.00      0.07      0.13        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.33      0.50         6\n",
      "          11       0.00      0.00      0.00        19\n",
      "          12       1.00      0.10      0.18        40\n",
      "          13       1.00      0.05      0.10        19\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.00      0.00      0.00        33\n",
      "          18       0.80      0.14      0.24        28\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.00      0.00      0.00        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       1.00      0.27      0.43        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       0.00      0.00      0.00         9\n",
      "          33       0.00      0.00      0.00        33\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.00      0.00      0.00        36\n",
      "          36       1.00      0.33      0.50        15\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       1.00      0.17      0.29         6\n",
      "          39       1.00      0.09      0.17        11\n",
      "          40       0.00      0.00      0.00        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       0.61      0.03      0.05       798\n",
      "   macro avg       0.20      0.04      0.06       798\n",
      "weighted avg       0.18      0.03      0.05       798\n",
      " samples avg       0.03      0.03      0.03       798\n",
      "\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.35      0.35        31\n",
      "           1       0.18      0.23      0.20        13\n",
      "           2       0.48      0.71      0.57        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.16      0.19      0.18        36\n",
      "           5       0.33      0.22      0.27         9\n",
      "           6       0.30      0.29      0.29        28\n",
      "           7       0.20      0.19      0.19        16\n",
      "           8       0.80      0.57      0.67        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.83      0.91         6\n",
      "          11       0.06      0.05      0.05        19\n",
      "          12       0.57      0.65      0.60        40\n",
      "          13       0.45      0.47      0.46        19\n",
      "          14       0.15      0.24      0.18        17\n",
      "          15       0.25      0.25      0.25         8\n",
      "          16       0.14      0.17      0.15         6\n",
      "          17       0.32      0.36      0.34        33\n",
      "          18       0.50      0.43      0.46        28\n",
      "          19       0.21      0.28      0.24        47\n",
      "          20       0.45      0.40      0.43        50\n",
      "          21       0.31      0.25      0.28        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.55      0.55      0.55        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.47      0.50      0.48        28\n",
      "          26       0.10      0.12      0.11         8\n",
      "          27       0.27      0.26      0.26        31\n",
      "          28       0.25      0.22      0.24        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.57      0.33      0.42        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       0.67      0.67      0.67         9\n",
      "          33       0.18      0.21      0.20        33\n",
      "          34       0.16      0.18      0.17        33\n",
      "          35       0.23      0.28      0.25        36\n",
      "          36       0.64      0.60      0.62        15\n",
      "          37       0.41      0.47      0.44        19\n",
      "          38       0.75      0.50      0.60         6\n",
      "          39       0.56      0.45      0.50        11\n",
      "          40       0.21      0.24      0.22        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.38      0.27      0.32        11\n",
      "\n",
      "   micro avg       0.32      0.33      0.32       798\n",
      "   macro avg       0.32      0.30      0.31       798\n",
      "weighted avg       0.33      0.33      0.33       798\n",
      " samples avg       0.28      0.35      0.30       798\n",
      "\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.50      0.07      0.12        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.50      0.07      0.12        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.83      0.36      0.50        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.83      0.91         6\n",
      "          11       0.00      0.00      0.00        19\n",
      "          12       0.33      0.03      0.05        40\n",
      "          13       0.83      0.26      0.40        19\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.40      0.06      0.11        33\n",
      "          18       1.00      0.21      0.35        28\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.67      0.04      0.08        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.33      0.09      0.14        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       1.00      0.04      0.07        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       1.00      0.17      0.29        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       1.00      0.33      0.50         9\n",
      "          33       0.60      0.18      0.28        33\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       1.00      0.06      0.11        36\n",
      "          36       1.00      0.40      0.57        15\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       0.00      0.00      0.00         6\n",
      "          39       1.00      0.18      0.31        11\n",
      "          40       1.00      0.08      0.15        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       1.00      0.27      0.43        11\n",
      "\n",
      "   micro avg       0.66      0.07      0.13       798\n",
      "   macro avg       0.35      0.09      0.13       798\n",
      "weighted avg       0.39      0.07      0.11       798\n",
      " samples avg       0.09      0.07      0.08       798\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing pipeline : No lemm\n",
    "pipeline_nolemm = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=100, random_state=1))])\n",
    "\n",
    "# WITHOUT LEMMATIZER\n",
    "run_classifiers(clfs, X, Y_mlb, pipeline_nolemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW TOKENIZER (ngram_range=1 lower the score of 1%)\n",
    "pipeline2 = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=newTokenizer, min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=150, random_state=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= RF =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       1.00      0.14      0.25        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.50      0.67         6\n",
      "          11       0.00      0.00      0.00        19\n",
      "          12       1.00      0.10      0.18        40\n",
      "          13       0.00      0.00      0.00        19\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.00      0.00      0.00        33\n",
      "          18       1.00      0.14      0.25        28\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.33      0.02      0.04        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       1.00      0.36      0.53        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       1.00      0.04      0.07        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       0.00      0.00      0.00         9\n",
      "          33       0.00      0.00      0.00        33\n",
      "          34       0.50      0.03      0.06        33\n",
      "          35       0.00      0.00      0.00        36\n",
      "          36       1.00      0.47      0.64        15\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       1.00      0.17      0.29         6\n",
      "          39       0.00      0.00      0.00        11\n",
      "          40       0.00      0.00      0.00        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       0.70      0.04      0.07       798\n",
      "   macro avg       0.21      0.05      0.07       798\n",
      "weighted avg       0.23      0.04      0.06       798\n",
      " samples avg       0.04      0.04      0.04       798\n",
      "\n",
      "\n",
      "\n",
      "======= MLP =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.45      0.41        31\n",
      "           1       0.33      0.31      0.32        13\n",
      "           2       0.56      0.36      0.43        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.24      0.28      0.26        36\n",
      "           5       0.40      0.22      0.29         9\n",
      "           6       0.23      0.29      0.25        28\n",
      "           7       0.11      0.12      0.11        16\n",
      "           8       0.56      0.64      0.60        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.83      0.91         6\n",
      "          11       0.33      0.16      0.21        19\n",
      "          12       0.48      0.50      0.49        40\n",
      "          13       0.56      0.47      0.51        19\n",
      "          14       0.18      0.24      0.21        17\n",
      "          15       0.43      0.38      0.40         8\n",
      "          16       0.50      0.17      0.25         6\n",
      "          17       0.40      0.36      0.38        33\n",
      "          18       0.52      0.46      0.49        28\n",
      "          19       0.24      0.23      0.24        47\n",
      "          20       0.44      0.46      0.45        50\n",
      "          21       0.36      0.31      0.33        16\n",
      "          22       0.25      0.20      0.22         5\n",
      "          23       0.86      0.55      0.67        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.52      0.46      0.49        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.35      0.26      0.30        31\n",
      "          28       0.11      0.07      0.09        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.42      0.42      0.42        12\n",
      "          31       0.40      0.40      0.40         5\n",
      "          32       0.62      0.56      0.59         9\n",
      "          33       0.22      0.24      0.23        33\n",
      "          34       0.15      0.18      0.16        33\n",
      "          35       0.25      0.28      0.26        36\n",
      "          36       0.64      0.60      0.62        15\n",
      "          37       0.40      0.42      0.41        19\n",
      "          38       0.75      0.50      0.60         6\n",
      "          39       0.71      0.45      0.56        11\n",
      "          40       0.21      0.24      0.23        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.44      0.36      0.40        11\n",
      "\n",
      "   micro avg       0.34      0.33      0.34       798\n",
      "   macro avg       0.36      0.31      0.33       798\n",
      "weighted avg       0.35      0.33      0.34       798\n",
      " samples avg       0.30      0.35      0.31       798\n",
      "\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       1.00      0.03      0.05        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.50      0.21      0.30        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       1.00      0.21      0.35        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.83      0.91         6\n",
      "          11       0.00      0.00      0.00        19\n",
      "          12       0.00      0.00      0.00        40\n",
      "          13       1.00      0.21      0.35        19\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.25      0.03      0.05        33\n",
      "          18       1.00      0.18      0.30        28\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.75      0.06      0.11        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.50      0.09      0.15        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       1.00      0.25      0.40        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       1.00      0.11      0.20         9\n",
      "          33       0.62      0.15      0.24        33\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.50      0.03      0.05        36\n",
      "          36       1.00      0.33      0.50        15\n",
      "          37       0.50      0.05      0.10        19\n",
      "          38       0.00      0.00      0.00         6\n",
      "          39       0.00      0.00      0.00        11\n",
      "          40       1.00      0.08      0.15        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.75      0.27      0.40        11\n",
      "\n",
      "   micro avg       0.65      0.06      0.11       798\n",
      "   macro avg       0.31      0.07      0.11       798\n",
      "weighted avg       0.36      0.06      0.10       798\n",
      " samples avg       0.07      0.06      0.07       798\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# New tokenizer (split maj words) (BEST RESULTS)\n",
    "run_classifiers(clfs, X, Y_mlb, pipeline2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= RF =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.50      0.07      0.12        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.33      0.50         6\n",
      "          11       0.00      0.00      0.00        19\n",
      "          12       0.83      0.12      0.22        40\n",
      "          13       1.00      0.05      0.10        19\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       1.00      0.12      0.22         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.00      0.00      0.00        33\n",
      "          18       1.00      0.18      0.30        28\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.33      0.02      0.04        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       1.00      0.36      0.53        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       1.00      0.07      0.13        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.50      0.03      0.06        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       0.00      0.00      0.00         9\n",
      "          33       0.00      0.00      0.00        33\n",
      "          34       0.67      0.06      0.11        33\n",
      "          35       0.00      0.00      0.00        36\n",
      "          36       1.00      0.40      0.57        15\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       1.00      0.17      0.29         6\n",
      "          39       0.00      0.00      0.00        11\n",
      "          40       0.50      0.04      0.07        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       1.00      0.09      0.17        11\n",
      "\n",
      "   micro avg       0.64      0.04      0.08       798\n",
      "   macro avg       0.29      0.05      0.08       798\n",
      "weighted avg       0.30      0.04      0.07       798\n",
      " samples avg       0.04      0.04      0.04       798\n",
      "\n",
      "\n",
      "\n",
      "======= BAGGING =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.10      0.15        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.50      0.07      0.12        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.14      0.03      0.05        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.20      0.07      0.11        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.77      0.71      0.74        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.83      0.91         6\n",
      "          11       0.20      0.05      0.08        19\n",
      "          12       0.50      0.17      0.26        40\n",
      "          13       0.50      0.16      0.24        19\n",
      "          14       0.09      0.06      0.07        17\n",
      "          15       0.50      0.12      0.20         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.00      0.00      0.00        33\n",
      "          18       0.43      0.32      0.37        28\n",
      "          19       0.19      0.06      0.10        47\n",
      "          20       0.38      0.10      0.16        50\n",
      "          21       0.50      0.12      0.20        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       1.00      0.36      0.53        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.71      0.18      0.29        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.36      0.13      0.19        31\n",
      "          28       0.50      0.04      0.07        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.67      0.17      0.27        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       0.00      0.00      0.00         9\n",
      "          33       0.20      0.06      0.09        33\n",
      "          34       0.31      0.12      0.17        33\n",
      "          35       0.40      0.06      0.10        36\n",
      "          36       0.85      0.73      0.79        15\n",
      "          37       0.57      0.21      0.31        19\n",
      "          38       0.29      0.33      0.31         6\n",
      "          39       0.67      0.18      0.29        11\n",
      "          40       0.25      0.04      0.07        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.50      0.18      0.27        11\n",
      "\n",
      "   micro avg       0.38      0.13      0.19       798\n",
      "   macro avg       0.31      0.13      0.17       798\n",
      "weighted avg       0.34      0.13      0.17       798\n",
      " samples avg       0.13      0.12      0.12       798\n",
      "\n",
      "\n",
      "\n",
      "======= ADABOOST =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.29      0.40        31\n",
      "           1       0.33      0.08      0.12        13\n",
      "           2       0.75      0.43      0.55        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.17      0.06      0.08        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.08      0.04      0.05        28\n",
      "           7       0.67      0.12      0.21        16\n",
      "           8       0.58      0.50      0.54        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      0.83      0.91         6\n",
      "          11       0.25      0.05      0.09        19\n",
      "          12       0.50      0.28      0.35        40\n",
      "          13       0.57      0.42      0.48        19\n",
      "          14       0.18      0.12      0.14        17\n",
      "          15       1.00      0.12      0.22         8\n",
      "          16       0.50      0.17      0.25         6\n",
      "          17       0.19      0.09      0.12        33\n",
      "          18       0.55      0.39      0.46        28\n",
      "          19       0.23      0.13      0.16        47\n",
      "          20       0.58      0.22      0.32        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       1.00      0.55      0.71        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.36      0.18      0.24        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.36      0.16      0.22        31\n",
      "          28       0.14      0.04      0.06        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.80      0.33      0.47        12\n",
      "          31       0.50      0.20      0.29         5\n",
      "          32       1.00      0.33      0.50         9\n",
      "          33       0.29      0.12      0.17        33\n",
      "          34       0.33      0.12      0.18        33\n",
      "          35       0.20      0.11      0.14        36\n",
      "          36       1.00      0.47      0.64        15\n",
      "          37       0.60      0.16      0.25        19\n",
      "          38       0.50      0.33      0.40         6\n",
      "          39       0.67      0.36      0.47        11\n",
      "          40       0.55      0.24      0.33        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.75      0.27      0.40        11\n",
      "\n",
      "   micro avg       0.43      0.19      0.26       798\n",
      "   macro avg       0.41      0.19      0.25       798\n",
      "weighted avg       0.40      0.19      0.25       798\n",
      " samples avg       0.20      0.20      0.20       798\n",
      "\n",
      "\n",
      "\n",
      "======= SVC =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.00      0.00      0.00        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       0.00      0.00      0.00         6\n",
      "          11       0.00      0.00      0.00        19\n",
      "          12       0.00      0.00      0.00        40\n",
      "          13       0.00      0.00      0.00        19\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.00      0.00      0.00        33\n",
      "          18       0.00      0.00      0.00        28\n",
      "          19       0.00      0.00      0.00        47\n",
      "          20       0.00      0.00      0.00        50\n",
      "          21       0.00      0.00      0.00        16\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.00      0.00      0.00        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.00      0.00      0.00        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       0.00      0.00      0.00         9\n",
      "          33       0.00      0.00      0.00        33\n",
      "          34       0.00      0.00      0.00        33\n",
      "          35       0.00      0.00      0.00        36\n",
      "          36       0.00      0.00      0.00        15\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       0.00      0.00      0.00         6\n",
      "          39       0.00      0.00      0.00        11\n",
      "          40       0.00      0.00      0.00        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       798\n",
      "   macro avg       0.00      0.00      0.00       798\n",
      "weighted avg       0.00      0.00      0.00       798\n",
      " samples avg       0.00      0.00      0.00       798\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# MULTILABEL with other classifiers with ONEVSREST\n",
    "clf_OvsR = {\n",
    "'RF': OneVsRestClassifier(RandomForestClassifier(n_estimators=100, random_state=1, n_jobs=-1)),\n",
    "'BAGGING': OneVsRestClassifier(BaggingClassifier(n_estimators=100,random_state=1)),\n",
    "'ADABOOST': OneVsRestClassifier(AdaBoostClassifier(n_estimators=100, random_state=1)),\n",
    "'SVC': OneVsRestClassifier(SVC(gamma='scale', decision_function_shape='ovo'))\n",
    "}\n",
    "\n",
    "run_classifiers(clf_OvsR, X, Y_mlb, pipeline2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= SVC =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.39      0.48        31\n",
      "           1       0.36      0.31      0.33        13\n",
      "           2       0.62      0.57      0.59        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.29      0.25      0.27        36\n",
      "           5       0.75      0.33      0.46         9\n",
      "           6       0.31      0.36      0.33        28\n",
      "           7       0.13      0.12      0.13        16\n",
      "           8       0.54      0.50      0.52        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      1.00      1.00         6\n",
      "          11       0.33      0.16      0.21        19\n",
      "          12       0.47      0.47      0.48        40\n",
      "          13       0.53      0.42      0.47        19\n",
      "          14       0.30      0.41      0.35        17\n",
      "          15       0.33      0.25      0.29         8\n",
      "          16       0.50      0.17      0.25         6\n",
      "          17       0.48      0.33      0.39        33\n",
      "          18       0.42      0.39      0.41        28\n",
      "          19       0.23      0.21      0.22        47\n",
      "          20       0.46      0.32      0.38        50\n",
      "          21       0.38      0.31      0.34        16\n",
      "          22       0.50      0.40      0.44         5\n",
      "          23       0.88      0.64      0.74        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.48      0.39      0.43        28\n",
      "          26       0.14      0.12      0.13         8\n",
      "          27       0.48      0.32      0.38        31\n",
      "          28       0.13      0.07      0.10        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.60      0.50      0.55        12\n",
      "          31       0.50      0.40      0.44         5\n",
      "          32       0.67      0.44      0.53         9\n",
      "          33       0.35      0.42      0.38        33\n",
      "          34       0.12      0.15      0.14        33\n",
      "          35       0.39      0.25      0.31        36\n",
      "          36       0.75      0.60      0.67        15\n",
      "          37       0.28      0.26      0.27        19\n",
      "          38       0.75      0.50      0.60         6\n",
      "          39       0.50      0.36      0.42        11\n",
      "          40       0.35      0.28      0.31        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.57      0.36      0.44        11\n",
      "\n",
      "   micro avg       0.39      0.32      0.36       798\n",
      "   macro avg       0.41      0.32      0.35       798\n",
      "weighted avg       0.40      0.32      0.35       798\n",
      " samples avg       0.31      0.34      0.32       798\n",
      "\n",
      "\n",
      "\n",
      "======= SVC2 =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.39      0.47        31\n",
      "           1       0.36      0.31      0.33        13\n",
      "           2       0.57      0.57      0.57        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.30      0.25      0.27        36\n",
      "           5       0.75      0.33      0.46         9\n",
      "           6       0.37      0.39      0.38        28\n",
      "           7       0.13      0.12      0.13        16\n",
      "           8       0.54      0.50      0.52        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      1.00      1.00         6\n",
      "          11       0.30      0.16      0.21        19\n",
      "          12       0.43      0.45      0.44        40\n",
      "          13       0.57      0.42      0.48        19\n",
      "          14       0.33      0.53      0.41        17\n",
      "          15       0.25      0.25      0.25         8\n",
      "          16       0.50      0.17      0.25         6\n",
      "          17       0.48      0.36      0.41        33\n",
      "          18       0.40      0.43      0.41        28\n",
      "          19       0.27      0.30      0.29        47\n",
      "          20       0.46      0.38      0.42        50\n",
      "          21       0.33      0.31      0.32        16\n",
      "          22       0.50      0.40      0.44         5\n",
      "          23       0.58      0.64      0.61        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.50      0.39      0.44        28\n",
      "          26       0.10      0.12      0.11         8\n",
      "          27       0.40      0.26      0.31        31\n",
      "          28       0.24      0.19      0.21        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.60      0.50      0.55        12\n",
      "          31       0.40      0.40      0.40         5\n",
      "          32       0.57      0.44      0.50         9\n",
      "          33       0.41      0.45      0.43        33\n",
      "          34       0.16      0.21      0.18        33\n",
      "          35       0.38      0.25      0.30        36\n",
      "          36       0.82      0.60      0.69        15\n",
      "          37       0.30      0.32      0.31        19\n",
      "          38       0.75      0.50      0.60         6\n",
      "          39       0.44      0.36      0.40        11\n",
      "          40       0.25      0.28      0.26        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.57      0.36      0.44        11\n",
      "\n",
      "   micro avg       0.39      0.34      0.36       798\n",
      "   macro avg       0.39      0.33      0.35       798\n",
      "weighted avg       0.40      0.34      0.36       798\n",
      " samples avg       0.32      0.36      0.32       798\n",
      "\n",
      "\n",
      "\n",
      "======= SVC_poly =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.16      0.26        31\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.67      0.29      0.40        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.21      0.11      0.14        28\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.56      0.36      0.43        14\n",
      "           9       0.02      0.40      0.03         5\n",
      "          10       1.00      0.67      0.80         6\n",
      "          11       0.17      0.05      0.08        19\n",
      "          12       0.64      0.23      0.33        40\n",
      "          13       0.57      0.21      0.31        19\n",
      "          14       0.24      0.24      0.24        17\n",
      "          15       0.33      0.25      0.29         8\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.27      0.09      0.14        33\n",
      "          18       0.46      0.21      0.29        28\n",
      "          19       0.15      0.04      0.07        47\n",
      "          20       0.43      0.12      0.19        50\n",
      "          21       0.29      0.12      0.17        16\n",
      "          22       1.00      0.20      0.33         5\n",
      "          23       0.70      0.64      0.67        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.42      0.18      0.25        28\n",
      "          26       0.00      0.00      0.00         8\n",
      "          27       0.60      0.10      0.17        31\n",
      "          28       0.00      0.00      0.00        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00        12\n",
      "          31       0.50      0.20      0.29         5\n",
      "          32       0.25      0.11      0.15         9\n",
      "          33       0.50      0.06      0.11        33\n",
      "          34       0.27      0.12      0.17        33\n",
      "          35       0.62      0.14      0.23        36\n",
      "          36       1.00      0.53      0.70        15\n",
      "          37       0.40      0.11      0.17        19\n",
      "          38       0.67      0.33      0.44         6\n",
      "          39       0.67      0.36      0.47        11\n",
      "          40       0.36      0.16      0.22        25\n",
      "          41       0.00      0.00      0.00        12\n",
      "          42       0.40      0.18      0.25        11\n",
      "\n",
      "   micro avg       0.28      0.14      0.19       798\n",
      "   macro avg       0.35      0.16      0.20       798\n",
      "weighted avg       0.37      0.14      0.19       798\n",
      " samples avg       0.12      0.14      0.12       798\n",
      "\n",
      "\n",
      "\n",
      "======= SVC_lin =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.52      0.52        31\n",
      "           1       0.24      0.31      0.27        13\n",
      "           2       0.57      0.57      0.57        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.25      0.39      0.30        36\n",
      "           5       0.38      0.33      0.35         9\n",
      "           6       0.27      0.46      0.34        28\n",
      "           7       0.10      0.19      0.13        16\n",
      "           8       0.56      0.64      0.60        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      1.00      1.00         6\n",
      "          11       0.22      0.21      0.22        19\n",
      "          12       0.35      0.57      0.43        40\n",
      "          13       0.55      0.58      0.56        19\n",
      "          14       0.27      0.47      0.34        17\n",
      "          15       0.27      0.38      0.32         8\n",
      "          16       0.17      0.17      0.17         6\n",
      "          17       0.33      0.45      0.38        33\n",
      "          18       0.42      0.54      0.47        28\n",
      "          19       0.19      0.36      0.25        47\n",
      "          20       0.38      0.46      0.41        50\n",
      "          21       0.31      0.31      0.31        16\n",
      "          22       0.50      0.40      0.44         5\n",
      "          23       0.47      0.64      0.54        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.27      0.46      0.34        28\n",
      "          26       0.12      0.12      0.12         8\n",
      "          27       0.28      0.32      0.30        31\n",
      "          28       0.19      0.26      0.22        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.45      0.42      0.43        12\n",
      "          31       0.38      0.60      0.46         5\n",
      "          32       0.36      0.56      0.43         9\n",
      "          33       0.30      0.48      0.37        33\n",
      "          34       0.12      0.27      0.16        33\n",
      "          35       0.17      0.28      0.21        36\n",
      "          36       0.77      0.67      0.71        15\n",
      "          37       0.35      0.42      0.38        19\n",
      "          38       0.75      0.50      0.60         6\n",
      "          39       0.25      0.36      0.30        11\n",
      "          40       0.12      0.28      0.17        25\n",
      "          41       0.12      0.17      0.14        12\n",
      "          42       0.38      0.27      0.32        11\n",
      "\n",
      "   micro avg       0.29      0.41      0.34       798\n",
      "   macro avg       0.32      0.38      0.34       798\n",
      "weighted avg       0.31      0.41      0.35       798\n",
      " samples avg       0.28      0.42      0.32       798\n",
      "\n",
      "\n",
      "\n",
      "======= SVC_best =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.58      0.54        31\n",
      "           1       0.19      0.31      0.24        13\n",
      "           2       0.57      0.57      0.57        14\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.25      0.42      0.32        36\n",
      "           5       0.30      0.33      0.32         9\n",
      "           6       0.28      0.46      0.35        28\n",
      "           7       0.10      0.19      0.13        16\n",
      "           8       0.56      0.64      0.60        14\n",
      "           9       0.00      0.00      0.00         5\n",
      "          10       1.00      1.00      1.00         6\n",
      "          11       0.26      0.26      0.26        19\n",
      "          12       0.35      0.60      0.44        40\n",
      "          13       0.55      0.58      0.56        19\n",
      "          14       0.26      0.53      0.35        17\n",
      "          15       0.25      0.38      0.30         8\n",
      "          16       0.17      0.17      0.17         6\n",
      "          17       0.33      0.55      0.41        33\n",
      "          18       0.41      0.57      0.48        28\n",
      "          19       0.17      0.38      0.24        47\n",
      "          20       0.35      0.46      0.40        50\n",
      "          21       0.25      0.31      0.28        16\n",
      "          22       0.40      0.40      0.40         5\n",
      "          23       0.47      0.64      0.54        11\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.27      0.50      0.35        28\n",
      "          26       0.11      0.12      0.12         8\n",
      "          27       0.24      0.32      0.28        31\n",
      "          28       0.18      0.26      0.21        27\n",
      "          29       0.00      0.00      0.00         2\n",
      "          30       0.45      0.42      0.43        12\n",
      "          31       0.29      0.40      0.33         5\n",
      "          32       0.33      0.56      0.42         9\n",
      "          33       0.29      0.45      0.35        33\n",
      "          34       0.13      0.33      0.18        33\n",
      "          35       0.15      0.31      0.20        36\n",
      "          36       0.77      0.67      0.71        15\n",
      "          37       0.30      0.42      0.35        19\n",
      "          38       0.75      0.50      0.60         6\n",
      "          39       0.24      0.36      0.29        11\n",
      "          40       0.12      0.28      0.17        25\n",
      "          41       0.15      0.25      0.19        12\n",
      "          42       0.31      0.36      0.33        11\n",
      "\n",
      "   micro avg       0.27      0.43      0.33       798\n",
      "   macro avg       0.30      0.39      0.34       798\n",
      "weighted avg       0.30      0.43      0.35       798\n",
      " samples avg       0.27      0.44      0.32       798\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# MULTILABEL with other classifiers with ONEVSREST and weight classes\n",
    "clf_OvsR_cb = {\n",
    "'SVC': OneVsRestClassifier(SVC(C=10, gamma=1, kernel=\"rbf\", decision_function_shape='ovo',class_weight=\"balanced\")),\n",
    "'SVC2': OneVsRestClassifier(SVC(C=5, gamma=1, kernel=\"rbf\", decision_function_shape='ovo',class_weight=\"balanced\")),\n",
    "'SVC_poly': OneVsRestClassifier(SVC(C=10, gamma=1, kernel=\"poly\", degree=5, decision_function_shape='ovo',class_weight=\"balanced\")),\n",
    "'SVC_lin': OneVsRestClassifier(SVC(C=10, gamma=1, kernel=\"linear\", decision_function_shape='ovo',class_weight=\"balanced\")),\n",
    "'SVC_best': OneVsRestClassifier(SVC(C=5, gamma=\"auto\", kernel=\"linear\", decision_function_shape='ovo',class_weight=\"balanced\"))\n",
    "}\n",
    "\n",
    "run_classifiers(clf_OvsR_cb, X, Y_mlb, pipeline2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22/07/2019 : Print only f1, precision and recall macro and micro. \n",
    "def run_classifiers_oneLine(clfs,X,Y, pipeline):\n",
    "    # Apply processing pipeline\n",
    "    X_proc = pipeline.fit_transform(X)\n",
    "    # Cross Validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    scoring = ['precision_macro', 'recall_macro', 'f1_macro', 'precision_micro', 'recall_micro']\n",
    "    for i in clfs:\n",
    "        try:\n",
    "            clf = clfs[i]\n",
    "            print(\"\\n\\n======= {0} =======\".format(i))\n",
    "            y_pred = cross_val_predict(clf, X_proc, Y, cv=kf)\n",
    "            print(\"f1-micro : \", f1_score(Y, y_pred, average=\"micro\"))\n",
    "            print(\"f1-macro : \", f1_score(Y, y_pred, average=\"macro\"))\n",
    "            print(\"precision-micro : \", precision_score(Y, y_pred, average=\"micro\"))\n",
    "            print(\"precision-macro : \", precision_score(Y, y_pred, average=\"macro\"))\n",
    "            print(\"recall-micro : \", recall_score(Y, y_pred, average=\"micro\"))\n",
    "            print(\"recall-macro : \", recall_score(Y, y_pred, average=\"macro\"))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "# Test and compare the 4 algorithms for the research paper\n",
    "clfs_alls = {\n",
    "    'SVC': OneVsRestClassifier(SVC(C=10, gamma=1, kernel=\"rbf\", decision_function_shape='ovo',class_weight=\"balanced\")),\n",
    "    #'BAGGING': OneVsRestClassifier(BaggingClassifier(n_estimators=100,random_state=1)),\n",
    "    #'ADABOOST': OneVsRestClassifier(AdaBoostClassifier(n_estimators=100, random_state=1)),\n",
    "    'RF': RandomForestClassifier(n_estimators=100, random_state=1, n_jobs=50),\n",
    "    'MLP': MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(100),random_state=1),\n",
    "    'KPPV': KNeighborsClassifier(n_neighbors=7)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= SVC =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-micro :  0.3557692307692307\n",
      "f1-macro :  0.35336359177227267\n",
      "precision-micro :  0.39361702127659576\n",
      "precision-macro :  0.40762880382551\n",
      "recall-micro :  0.32456140350877194\n",
      "recall-macro :  0.32039621300152804\n",
      "\n",
      "\n",
      "======= RF =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-micro :  0.06682577565632458\n",
      "f1-macro :  0.06901721691481266\n",
      "precision-micro :  0.7\n",
      "precision-macro :  0.20542635658914726\n",
      "recall-micro :  0.03508771929824561\n",
      "recall-macro :  0.04578375113258834\n",
      "\n",
      "\n",
      "======= MLP =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-micro :  0.3373801916932907\n",
      "f1-macro :  0.32982596739991815\n",
      "precision-micro :  0.34419817470664926\n",
      "precision-macro :  0.3614551191673218\n",
      "recall-micro :  0.3308270676691729\n",
      "recall-macro :  0.3125979748071629\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "f1-micro :  0.11428571428571428\n",
      "f1-macro :  0.10757846767376039\n",
      "precision-micro :  0.6493506493506493\n",
      "precision-macro :  0.311046511627907\n",
      "recall-micro :  0.06265664160401002\n",
      "recall-macro :  0.07300206117831576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "run_classifiers_oneLine(clfs_alls, X, Y_mlb, pipeline2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= SVC =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-micro :  0.3091216216216216\n",
      "f1-macro :  0.31245587351312865\n",
      "precision-micro :  0.4740932642487047\n",
      "precision-macro :  0.4619135262528377\n",
      "recall-micro :  0.22932330827067668\n",
      "recall-macro :  0.2469063215754428\n",
      "\n",
      "\n",
      "======= RF =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-micro :  0.041312272174969626\n",
      "f1-macro :  0.04288188020077235\n",
      "precision-micro :  0.68\n",
      "precision-macro :  0.11627906976744186\n",
      "recall-micro :  0.021303258145363407\n",
      "recall-macro :  0.02747659317426759\n",
      "\n",
      "\n",
      "======= MLP =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-micro :  0.28774928774928776\n",
      "f1-macro :  0.2861826157158443\n",
      "precision-micro :  0.3333333333333333\n",
      "precision-macro :  0.36331070264073284\n",
      "recall-micro :  0.2531328320802005\n",
      "recall-macro :  0.24769069693987572\n",
      "\n",
      "\n",
      "======= KPPV =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-micro :  0.11098527746319366\n",
      "f1-macro :  0.10192207029590471\n",
      "precision-micro :  0.5764705882352941\n",
      "precision-macro :  0.2554909560723514\n",
      "recall-micro :  0.06140350877192982\n",
      "recall-macro :  0.07288901870603218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Test SVD = 300\n",
    "pipeline_SVD300 = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=newTokenizer, min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=300, random_state=1))])\n",
    "\n",
    "run_classifiers_oneLine(clfs_alls, X, Y_mlb, pipeline_SVD300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======= SVC =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 24 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-micro :  0.3099688473520249\n",
      "f1-macro :  0.30842251505823537\n",
      "precision-micro :  0.2248587570621469\n",
      "precision-macro :  0.25007437062788584\n",
      "recall-micro :  0.49874686716791977\n",
      "recall-macro :  0.43667438227054367\n",
      "\n",
      "\n",
      "======= RF =======\n",
      "f1-micro :  0.12399540757749714\n",
      "f1-macro :  0.11954613153164868\n",
      "precision-micro :  0.7397260273972602\n",
      "precision-macro :  0.33242894056847544\n",
      "recall-micro :  0.06766917293233082\n",
      "recall-macro :  0.08171947122118876\n",
      "\n",
      "\n",
      "======= MLP =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-micro :  0.3278271918678526\n",
      "f1-macro :  0.31706586792828495\n",
      "precision-micro :  0.3324742268041237\n",
      "precision-macro :  0.3384763975171446\n",
      "recall-micro :  0.3233082706766917\n",
      "recall-macro :  0.3066825620954641\n",
      "\n",
      "\n",
      "======= KPPV =======\n",
      "f1-micro :  0.1668472372697725\n",
      "f1-macro :  0.15382053644410235\n",
      "precision-micro :  0.616\n",
      "precision-macro :  0.3488372093023256\n",
      "recall-micro :  0.09649122807017543\n",
      "recall-macro :  0.10748834376702288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Test SVD = 50\n",
    "pipeline_SVD50 = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=newTokenizer, min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=50, random_state=1))])\n",
    "\n",
    "run_classifiers_oneLine(clfs_alls, X, Y_mlb, pipeline_SVD50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "### KERAS MLP with class balanced ###\n",
    "\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will set the model for calling it with the Scikit learn API\n",
    "\n",
    "np.random.seed(1)\n",
    "epochs = 200\n",
    "batch_size = 10\n",
    "alpha=1e-5\n",
    "\n",
    "# Create MLP model\n",
    "def create_model(input_dim):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(100, input_dim=input_dim, kernel_regularizer=regularizers.l2(1e-5),\n",
    "                   activity_regularizer=regularizers.l2(1e-5)))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # Final layer\n",
    "    model.add(Dense(len(Y_mlb[0])))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weights\n",
    "class_weights = np.apply_along_axis(np.count_nonzero, 0, Y_mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = create_model(input_dim=len(X_proc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data\n",
    "X_proc = pipeline2.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_proc, Y_mlb, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 524 samples, validate on 132 samples\n",
      "Epoch 1/200\n",
      "524/524 [==============================] - 10s 19ms/step - loss: 0.6816 - categorical_accuracy: 0.0286 - val_loss: 0.6625 - val_categorical_accuracy: 0.0379\n",
      "Epoch 2/200\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.6415 - categorical_accuracy: 0.0324 - val_loss: 0.6159 - val_categorical_accuracy: 0.0303\n",
      "Epoch 3/200\n",
      "524/524 [==============================] - 0s 302us/step - loss: 0.5826 - categorical_accuracy: 0.0401 - val_loss: 0.5446 - val_categorical_accuracy: 0.0379\n",
      "Epoch 4/200\n",
      "524/524 [==============================] - 0s 271us/step - loss: 0.4965 - categorical_accuracy: 0.0515 - val_loss: 0.4485 - val_categorical_accuracy: 0.0455\n",
      "Epoch 5/200\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.3897 - categorical_accuracy: 0.0382 - val_loss: 0.3452 - val_categorical_accuracy: 0.0303\n",
      "Epoch 6/200\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.2906 - categorical_accuracy: 0.0363 - val_loss: 0.2576 - val_categorical_accuracy: 0.0227\n",
      "Epoch 7/200\n",
      "524/524 [==============================] - 0s 305us/step - loss: 0.2157 - categorical_accuracy: 0.0324 - val_loss: 0.2001 - val_categorical_accuracy: 0.0227\n",
      "Epoch 8/200\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.1712 - categorical_accuracy: 0.0401 - val_loss: 0.1680 - val_categorical_accuracy: 0.0152\n",
      "Epoch 9/200\n",
      "524/524 [==============================] - 0s 312us/step - loss: 0.1484 - categorical_accuracy: 0.0668 - val_loss: 0.1513 - val_categorical_accuracy: 0.0530\n",
      "Epoch 10/200\n",
      "524/524 [==============================] - 0s 301us/step - loss: 0.1376 - categorical_accuracy: 0.0668 - val_loss: 0.1429 - val_categorical_accuracy: 0.0455\n",
      "Epoch 11/200\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.1315 - categorical_accuracy: 0.0897 - val_loss: 0.1383 - val_categorical_accuracy: 0.0606\n",
      "Epoch 12/200\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.1283 - categorical_accuracy: 0.0897 - val_loss: 0.1358 - val_categorical_accuracy: 0.0606\n",
      "Epoch 13/200\n",
      "524/524 [==============================] - 0s 322us/step - loss: 0.1262 - categorical_accuracy: 0.1050 - val_loss: 0.1341 - val_categorical_accuracy: 0.0606\n",
      "Epoch 14/200\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.1248 - categorical_accuracy: 0.0897 - val_loss: 0.1331 - val_categorical_accuracy: 0.0682\n",
      "Epoch 15/200\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.1241 - categorical_accuracy: 0.1031 - val_loss: 0.1323 - val_categorical_accuracy: 0.0682\n",
      "Epoch 16/200\n",
      "524/524 [==============================] - 0s 332us/step - loss: 0.1232 - categorical_accuracy: 0.0935 - val_loss: 0.1317 - val_categorical_accuracy: 0.0758\n",
      "Epoch 17/200\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.1222 - categorical_accuracy: 0.1126 - val_loss: 0.1312 - val_categorical_accuracy: 0.0758\n",
      "Epoch 18/200\n",
      "524/524 [==============================] - 0s 259us/step - loss: 0.1215 - categorical_accuracy: 0.1279 - val_loss: 0.1308 - val_categorical_accuracy: 0.0758\n",
      "Epoch 19/200\n",
      "524/524 [==============================] - 0s 306us/step - loss: 0.1212 - categorical_accuracy: 0.1145 - val_loss: 0.1305 - val_categorical_accuracy: 0.0758\n",
      "Epoch 20/200\n",
      "524/524 [==============================] - 0s 348us/step - loss: 0.1207 - categorical_accuracy: 0.1317 - val_loss: 0.1301 - val_categorical_accuracy: 0.0833\n",
      "Epoch 21/200\n",
      "524/524 [==============================] - 0s 302us/step - loss: 0.1202 - categorical_accuracy: 0.1336 - val_loss: 0.1299 - val_categorical_accuracy: 0.0833\n",
      "Epoch 22/200\n",
      "524/524 [==============================] - 0s 296us/step - loss: 0.1200 - categorical_accuracy: 0.1279 - val_loss: 0.1296 - val_categorical_accuracy: 0.0833\n",
      "Epoch 23/200\n",
      "524/524 [==============================] - 0s 308us/step - loss: 0.1196 - categorical_accuracy: 0.1374 - val_loss: 0.1294 - val_categorical_accuracy: 0.0833\n",
      "Epoch 24/200\n",
      "524/524 [==============================] - 0s 285us/step - loss: 0.1185 - categorical_accuracy: 0.1393 - val_loss: 0.1291 - val_categorical_accuracy: 0.0833\n",
      "Epoch 25/200\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.1184 - categorical_accuracy: 0.1469 - val_loss: 0.1289 - val_categorical_accuracy: 0.0758\n",
      "Epoch 26/200\n",
      "524/524 [==============================] - 0s 315us/step - loss: 0.1180 - categorical_accuracy: 0.1450 - val_loss: 0.1286 - val_categorical_accuracy: 0.0833\n",
      "Epoch 27/200\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.1173 - categorical_accuracy: 0.1546 - val_loss: 0.1284 - val_categorical_accuracy: 0.0833\n",
      "Epoch 28/200\n",
      "524/524 [==============================] - 0s 300us/step - loss: 0.1170 - categorical_accuracy: 0.1660 - val_loss: 0.1281 - val_categorical_accuracy: 0.0833\n",
      "Epoch 29/200\n",
      "524/524 [==============================] - 0s 266us/step - loss: 0.1166 - categorical_accuracy: 0.1870 - val_loss: 0.1277 - val_categorical_accuracy: 0.0909\n",
      "Epoch 30/200\n",
      "524/524 [==============================] - 0s 303us/step - loss: 0.1159 - categorical_accuracy: 0.1966 - val_loss: 0.1275 - val_categorical_accuracy: 0.1061\n",
      "Epoch 31/200\n",
      "524/524 [==============================] - 0s 296us/step - loss: 0.1153 - categorical_accuracy: 0.2042 - val_loss: 0.1273 - val_categorical_accuracy: 0.1061\n",
      "Epoch 32/200\n",
      "524/524 [==============================] - 0s 306us/step - loss: 0.1147 - categorical_accuracy: 0.2042 - val_loss: 0.1270 - val_categorical_accuracy: 0.1061\n",
      "Epoch 33/200\n",
      "524/524 [==============================] - 0s 286us/step - loss: 0.1142 - categorical_accuracy: 0.2023 - val_loss: 0.1267 - val_categorical_accuracy: 0.0985\n",
      "Epoch 34/200\n",
      "524/524 [==============================] - 0s 309us/step - loss: 0.1137 - categorical_accuracy: 0.2118 - val_loss: 0.1265 - val_categorical_accuracy: 0.1061\n",
      "Epoch 35/200\n",
      "524/524 [==============================] - 0s 356us/step - loss: 0.1131 - categorical_accuracy: 0.2309 - val_loss: 0.1261 - val_categorical_accuracy: 0.1136\n",
      "Epoch 36/200\n",
      "524/524 [==============================] - 0s 305us/step - loss: 0.1124 - categorical_accuracy: 0.2252 - val_loss: 0.1258 - val_categorical_accuracy: 0.1136\n",
      "Epoch 37/200\n",
      "524/524 [==============================] - 0s 299us/step - loss: 0.1117 - categorical_accuracy: 0.2538 - val_loss: 0.1255 - val_categorical_accuracy: 0.1212\n",
      "Epoch 38/200\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.1111 - categorical_accuracy: 0.2576 - val_loss: 0.1253 - val_categorical_accuracy: 0.1364\n",
      "Epoch 39/200\n",
      "524/524 [==============================] - 0s 288us/step - loss: 0.1104 - categorical_accuracy: 0.2767 - val_loss: 0.1250 - val_categorical_accuracy: 0.1364\n",
      "Epoch 40/200\n",
      "524/524 [==============================] - 0s 303us/step - loss: 0.1097 - categorical_accuracy: 0.2576 - val_loss: 0.1246 - val_categorical_accuracy: 0.1288\n",
      "Epoch 41/200\n",
      "524/524 [==============================] - 0s 291us/step - loss: 0.1087 - categorical_accuracy: 0.2996 - val_loss: 0.1242 - val_categorical_accuracy: 0.1364\n",
      "Epoch 42/200\n",
      "524/524 [==============================] - 0s 314us/step - loss: 0.1083 - categorical_accuracy: 0.2977 - val_loss: 0.1239 - val_categorical_accuracy: 0.1364\n",
      "Epoch 43/200\n",
      "524/524 [==============================] - 0s 312us/step - loss: 0.1074 - categorical_accuracy: 0.3015 - val_loss: 0.1234 - val_categorical_accuracy: 0.1439\n",
      "Epoch 44/200\n",
      "524/524 [==============================] - 0s 295us/step - loss: 0.1065 - categorical_accuracy: 0.3282 - val_loss: 0.1230 - val_categorical_accuracy: 0.1742\n",
      "Epoch 45/200\n",
      "524/524 [==============================] - 0s 310us/step - loss: 0.1061 - categorical_accuracy: 0.3473 - val_loss: 0.1226 - val_categorical_accuracy: 0.1742\n",
      "Epoch 46/200\n",
      "524/524 [==============================] - 0s 291us/step - loss: 0.1050 - categorical_accuracy: 0.3588 - val_loss: 0.1223 - val_categorical_accuracy: 0.1667\n",
      "Epoch 47/200\n",
      "524/524 [==============================] - 0s 296us/step - loss: 0.1045 - categorical_accuracy: 0.3588 - val_loss: 0.1219 - val_categorical_accuracy: 0.1742\n",
      "Epoch 48/200\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.1041 - categorical_accuracy: 0.3760 - val_loss: 0.1216 - val_categorical_accuracy: 0.1894\n",
      "Epoch 49/200\n",
      "524/524 [==============================] - 0s 314us/step - loss: 0.1030 - categorical_accuracy: 0.3989 - val_loss: 0.1211 - val_categorical_accuracy: 0.1818\n",
      "Epoch 50/200\n",
      "524/524 [==============================] - 0s 281us/step - loss: 0.1023 - categorical_accuracy: 0.4008 - val_loss: 0.1206 - val_categorical_accuracy: 0.1894\n",
      "Epoch 51/200\n",
      "524/524 [==============================] - 0s 329us/step - loss: 0.1009 - categorical_accuracy: 0.4027 - val_loss: 0.1202 - val_categorical_accuracy: 0.1894\n",
      "Epoch 52/200\n",
      "524/524 [==============================] - 0s 301us/step - loss: 0.1003 - categorical_accuracy: 0.4275 - val_loss: 0.1198 - val_categorical_accuracy: 0.2045\n",
      "Epoch 53/200\n",
      "524/524 [==============================] - 0s 324us/step - loss: 0.0992 - categorical_accuracy: 0.4504 - val_loss: 0.1194 - val_categorical_accuracy: 0.2348\n",
      "Epoch 54/200\n",
      "524/524 [==============================] - 0s 369us/step - loss: 0.0990 - categorical_accuracy: 0.4427 - val_loss: 0.1190 - val_categorical_accuracy: 0.2197\n",
      "Epoch 55/200\n",
      "524/524 [==============================] - 0s 326us/step - loss: 0.0978 - categorical_accuracy: 0.4523 - val_loss: 0.1186 - val_categorical_accuracy: 0.2348\n",
      "Epoch 56/200\n",
      "524/524 [==============================] - 0s 277us/step - loss: 0.0972 - categorical_accuracy: 0.4599 - val_loss: 0.1181 - val_categorical_accuracy: 0.2500\n",
      "Epoch 57/200\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0958 - categorical_accuracy: 0.4943 - val_loss: 0.1178 - val_categorical_accuracy: 0.2424\n",
      "Epoch 58/200\n",
      "524/524 [==============================] - 0s 288us/step - loss: 0.0952 - categorical_accuracy: 0.4790 - val_loss: 0.1173 - val_categorical_accuracy: 0.2500\n",
      "Epoch 59/200\n",
      "524/524 [==============================] - 0s 290us/step - loss: 0.0945 - categorical_accuracy: 0.4828 - val_loss: 0.1169 - val_categorical_accuracy: 0.2576\n",
      "Epoch 60/200\n",
      "524/524 [==============================] - 0s 296us/step - loss: 0.0940 - categorical_accuracy: 0.4924 - val_loss: 0.1166 - val_categorical_accuracy: 0.2576\n",
      "Epoch 61/200\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0929 - categorical_accuracy: 0.5115 - val_loss: 0.1163 - val_categorical_accuracy: 0.2500\n",
      "Epoch 62/200\n",
      "524/524 [==============================] - 0s 320us/step - loss: 0.0918 - categorical_accuracy: 0.5095 - val_loss: 0.1159 - val_categorical_accuracy: 0.2576\n",
      "Epoch 63/200\n",
      "524/524 [==============================] - 0s 288us/step - loss: 0.0911 - categorical_accuracy: 0.5229 - val_loss: 0.1154 - val_categorical_accuracy: 0.2727\n",
      "Epoch 64/200\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0906 - categorical_accuracy: 0.5267 - val_loss: 0.1150 - val_categorical_accuracy: 0.2500\n",
      "Epoch 65/200\n",
      "524/524 [==============================] - 0s 304us/step - loss: 0.0894 - categorical_accuracy: 0.5210 - val_loss: 0.1148 - val_categorical_accuracy: 0.2500\n",
      "Epoch 66/200\n",
      "524/524 [==============================] - 0s 304us/step - loss: 0.0885 - categorical_accuracy: 0.5477 - val_loss: 0.1143 - val_categorical_accuracy: 0.2727\n",
      "Epoch 67/200\n",
      "524/524 [==============================] - 0s 303us/step - loss: 0.0878 - categorical_accuracy: 0.5382 - val_loss: 0.1139 - val_categorical_accuracy: 0.2500\n",
      "Epoch 68/200\n",
      "524/524 [==============================] - 0s 290us/step - loss: 0.0870 - categorical_accuracy: 0.5553 - val_loss: 0.1137 - val_categorical_accuracy: 0.2652\n",
      "Epoch 69/200\n",
      "524/524 [==============================] - 0s 287us/step - loss: 0.0861 - categorical_accuracy: 0.5439 - val_loss: 0.1133 - val_categorical_accuracy: 0.2576\n",
      "Epoch 70/200\n",
      "524/524 [==============================] - 0s 294us/step - loss: 0.0853 - categorical_accuracy: 0.5649 - val_loss: 0.1130 - val_categorical_accuracy: 0.2652\n",
      "Epoch 71/200\n",
      "524/524 [==============================] - 0s 321us/step - loss: 0.0847 - categorical_accuracy: 0.5573 - val_loss: 0.1128 - val_categorical_accuracy: 0.2727\n",
      "Epoch 72/200\n",
      "524/524 [==============================] - 0s 288us/step - loss: 0.0844 - categorical_accuracy: 0.5763 - val_loss: 0.1125 - val_categorical_accuracy: 0.2803\n",
      "Epoch 73/200\n",
      "524/524 [==============================] - 0s 269us/step - loss: 0.0838 - categorical_accuracy: 0.5630 - val_loss: 0.1121 - val_categorical_accuracy: 0.2803\n",
      "Epoch 74/200\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0825 - categorical_accuracy: 0.5649 - val_loss: 0.1118 - val_categorical_accuracy: 0.2727\n",
      "Epoch 75/200\n",
      "524/524 [==============================] - 0s 310us/step - loss: 0.0823 - categorical_accuracy: 0.5573 - val_loss: 0.1117 - val_categorical_accuracy: 0.2803\n",
      "Epoch 76/200\n",
      "524/524 [==============================] - 0s 311us/step - loss: 0.0813 - categorical_accuracy: 0.5687 - val_loss: 0.1114 - val_categorical_accuracy: 0.2803\n",
      "Epoch 77/200\n",
      "524/524 [==============================] - 0s 306us/step - loss: 0.0805 - categorical_accuracy: 0.5687 - val_loss: 0.1113 - val_categorical_accuracy: 0.2803\n",
      "Epoch 78/200\n",
      "524/524 [==============================] - 0s 304us/step - loss: 0.0798 - categorical_accuracy: 0.5821 - val_loss: 0.1110 - val_categorical_accuracy: 0.2879\n",
      "Epoch 79/200\n",
      "524/524 [==============================] - 0s 263us/step - loss: 0.0792 - categorical_accuracy: 0.5954 - val_loss: 0.1107 - val_categorical_accuracy: 0.2879\n",
      "Epoch 80/200\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0786 - categorical_accuracy: 0.6011 - val_loss: 0.1105 - val_categorical_accuracy: 0.2879\n",
      "Epoch 81/200\n",
      "524/524 [==============================] - 0s 313us/step - loss: 0.0783 - categorical_accuracy: 0.5802 - val_loss: 0.1101 - val_categorical_accuracy: 0.2803\n",
      "Epoch 82/200\n",
      "524/524 [==============================] - 0s 308us/step - loss: 0.0770 - categorical_accuracy: 0.6011 - val_loss: 0.1099 - val_categorical_accuracy: 0.2803\n",
      "Epoch 83/200\n",
      "524/524 [==============================] - 0s 313us/step - loss: 0.0765 - categorical_accuracy: 0.6221 - val_loss: 0.1098 - val_categorical_accuracy: 0.2803\n",
      "Epoch 84/200\n",
      "524/524 [==============================] - 0s 289us/step - loss: 0.0768 - categorical_accuracy: 0.6050 - val_loss: 0.1096 - val_categorical_accuracy: 0.2803\n",
      "Epoch 85/200\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0757 - categorical_accuracy: 0.6088 - val_loss: 0.1095 - val_categorical_accuracy: 0.2955\n",
      "Epoch 86/200\n",
      "524/524 [==============================] - 0s 309us/step - loss: 0.0752 - categorical_accuracy: 0.6107 - val_loss: 0.1093 - val_categorical_accuracy: 0.2879\n",
      "Epoch 87/200\n",
      "524/524 [==============================] - 0s 285us/step - loss: 0.0747 - categorical_accuracy: 0.6126 - val_loss: 0.1092 - val_categorical_accuracy: 0.2803\n",
      "Epoch 88/200\n",
      "524/524 [==============================] - 0s 314us/step - loss: 0.0743 - categorical_accuracy: 0.6164 - val_loss: 0.1090 - val_categorical_accuracy: 0.2879\n",
      "Epoch 89/200\n",
      "524/524 [==============================] - 0s 311us/step - loss: 0.0739 - categorical_accuracy: 0.6202 - val_loss: 0.1089 - val_categorical_accuracy: 0.2879\n",
      "Epoch 90/200\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0730 - categorical_accuracy: 0.6260 - val_loss: 0.1088 - val_categorical_accuracy: 0.2879\n",
      "Epoch 91/200\n",
      "524/524 [==============================] - 0s 304us/step - loss: 0.0722 - categorical_accuracy: 0.6374 - val_loss: 0.1086 - val_categorical_accuracy: 0.2879\n",
      "Epoch 92/200\n",
      "524/524 [==============================] - 0s 311us/step - loss: 0.0722 - categorical_accuracy: 0.6298 - val_loss: 0.1084 - val_categorical_accuracy: 0.2803\n",
      "Epoch 93/200\n",
      "524/524 [==============================] - 0s 281us/step - loss: 0.0717 - categorical_accuracy: 0.6374 - val_loss: 0.1083 - val_categorical_accuracy: 0.2879\n",
      "Epoch 94/200\n",
      "524/524 [==============================] - 0s 258us/step - loss: 0.0711 - categorical_accuracy: 0.6183 - val_loss: 0.1083 - val_categorical_accuracy: 0.2803\n",
      "Epoch 95/200\n",
      "524/524 [==============================] - 0s 291us/step - loss: 0.0704 - categorical_accuracy: 0.6412 - val_loss: 0.1081 - val_categorical_accuracy: 0.2879\n",
      "Epoch 96/200\n",
      "524/524 [==============================] - 0s 295us/step - loss: 0.0702 - categorical_accuracy: 0.6260 - val_loss: 0.1081 - val_categorical_accuracy: 0.2879\n",
      "Epoch 97/200\n",
      "524/524 [==============================] - 0s 316us/step - loss: 0.0699 - categorical_accuracy: 0.6374 - val_loss: 0.1080 - val_categorical_accuracy: 0.2879\n",
      "Epoch 98/200\n",
      "524/524 [==============================] - 0s 287us/step - loss: 0.0691 - categorical_accuracy: 0.6527 - val_loss: 0.1079 - val_categorical_accuracy: 0.2879\n",
      "Epoch 99/200\n",
      "524/524 [==============================] - 0s 297us/step - loss: 0.0689 - categorical_accuracy: 0.6546 - val_loss: 0.1078 - val_categorical_accuracy: 0.2879\n",
      "Epoch 100/200\n",
      "524/524 [==============================] - 0s 310us/step - loss: 0.0681 - categorical_accuracy: 0.6260 - val_loss: 0.1078 - val_categorical_accuracy: 0.2879\n",
      "Epoch 101/200\n",
      "524/524 [==============================] - 0s 313us/step - loss: 0.0686 - categorical_accuracy: 0.6412 - val_loss: 0.1078 - val_categorical_accuracy: 0.2879\n",
      "Epoch 102/200\n",
      "524/524 [==============================] - 0s 286us/step - loss: 0.0679 - categorical_accuracy: 0.6584 - val_loss: 0.1078 - val_categorical_accuracy: 0.3030\n",
      "Epoch 103/200\n",
      "524/524 [==============================] - 0s 289us/step - loss: 0.0671 - categorical_accuracy: 0.6718 - val_loss: 0.1076 - val_categorical_accuracy: 0.3030\n",
      "Epoch 104/200\n",
      "524/524 [==============================] - 0s 290us/step - loss: 0.0669 - categorical_accuracy: 0.6698 - val_loss: 0.1077 - val_categorical_accuracy: 0.2879\n",
      "Epoch 105/200\n",
      "524/524 [==============================] - 0s 281us/step - loss: 0.0671 - categorical_accuracy: 0.6489 - val_loss: 0.1076 - val_categorical_accuracy: 0.2955\n",
      "Epoch 106/200\n",
      "524/524 [==============================] - 0s 271us/step - loss: 0.0657 - categorical_accuracy: 0.6756 - val_loss: 0.1076 - val_categorical_accuracy: 0.3030\n",
      "Epoch 107/200\n",
      "524/524 [==============================] - 0s 313us/step - loss: 0.0662 - categorical_accuracy: 0.6584 - val_loss: 0.1074 - val_categorical_accuracy: 0.3106\n",
      "Epoch 108/200\n",
      "524/524 [==============================] - 0s 299us/step - loss: 0.0657 - categorical_accuracy: 0.6489 - val_loss: 0.1075 - val_categorical_accuracy: 0.3182\n",
      "Epoch 109/200\n",
      "524/524 [==============================] - 0s 302us/step - loss: 0.0649 - categorical_accuracy: 0.6737 - val_loss: 0.1076 - val_categorical_accuracy: 0.3333\n",
      "Epoch 110/200\n",
      "524/524 [==============================] - 0s 306us/step - loss: 0.0646 - categorical_accuracy: 0.6698 - val_loss: 0.1074 - val_categorical_accuracy: 0.3409\n",
      "Epoch 111/200\n",
      "524/524 [==============================] - 0s 299us/step - loss: 0.0643 - categorical_accuracy: 0.6870 - val_loss: 0.1075 - val_categorical_accuracy: 0.3409\n",
      "Epoch 112/200\n",
      "524/524 [==============================] - 0s 294us/step - loss: 0.0642 - categorical_accuracy: 0.6660 - val_loss: 0.1076 - val_categorical_accuracy: 0.3258\n",
      "Epoch 113/200\n",
      "524/524 [==============================] - 0s 288us/step - loss: 0.0635 - categorical_accuracy: 0.6794 - val_loss: 0.1076 - val_categorical_accuracy: 0.3333\n",
      "Epoch 114/200\n",
      "524/524 [==============================] - 0s 270us/step - loss: 0.0630 - categorical_accuracy: 0.6908 - val_loss: 0.1075 - val_categorical_accuracy: 0.3409\n",
      "Epoch 115/200\n",
      "524/524 [==============================] - 0s 311us/step - loss: 0.0628 - categorical_accuracy: 0.6794 - val_loss: 0.1074 - val_categorical_accuracy: 0.3409\n",
      "Epoch 116/200\n",
      "524/524 [==============================] - 0s 288us/step - loss: 0.0627 - categorical_accuracy: 0.6718 - val_loss: 0.1075 - val_categorical_accuracy: 0.3333\n",
      "Epoch 117/200\n",
      "524/524 [==============================] - 0s 284us/step - loss: 0.0626 - categorical_accuracy: 0.6813 - val_loss: 0.1075 - val_categorical_accuracy: 0.3333\n",
      "Epoch 118/200\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0621 - categorical_accuracy: 0.6813 - val_loss: 0.1075 - val_categorical_accuracy: 0.3258\n",
      "Epoch 119/200\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0619 - categorical_accuracy: 0.7118 - val_loss: 0.1074 - val_categorical_accuracy: 0.3258\n",
      "Epoch 120/200\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0609 - categorical_accuracy: 0.6908 - val_loss: 0.1076 - val_categorical_accuracy: 0.3333\n",
      "Epoch 121/200\n",
      "524/524 [==============================] - 0s 272us/step - loss: 0.0607 - categorical_accuracy: 0.7099 - val_loss: 0.1077 - val_categorical_accuracy: 0.3182\n",
      "Epoch 122/200\n",
      "524/524 [==============================] - 0s 312us/step - loss: 0.0614 - categorical_accuracy: 0.6889 - val_loss: 0.1077 - val_categorical_accuracy: 0.3333\n",
      "Epoch 123/200\n",
      "524/524 [==============================] - 0s 306us/step - loss: 0.0604 - categorical_accuracy: 0.7080 - val_loss: 0.1076 - val_categorical_accuracy: 0.3333\n",
      "Epoch 124/200\n",
      "524/524 [==============================] - 0s 310us/step - loss: 0.0598 - categorical_accuracy: 0.7156 - val_loss: 0.1076 - val_categorical_accuracy: 0.3409\n",
      "Epoch 125/200\n",
      "524/524 [==============================] - 0s 290us/step - loss: 0.0598 - categorical_accuracy: 0.7176 - val_loss: 0.1077 - val_categorical_accuracy: 0.3409\n",
      "Epoch 126/200\n",
      "524/524 [==============================] - 0s 278us/step - loss: 0.0590 - categorical_accuracy: 0.7099 - val_loss: 0.1076 - val_categorical_accuracy: 0.3409\n",
      "Epoch 127/200\n",
      "524/524 [==============================] - 0s 341us/step - loss: 0.0591 - categorical_accuracy: 0.7176 - val_loss: 0.1076 - val_categorical_accuracy: 0.3409\n",
      "Epoch 128/200\n",
      "524/524 [==============================] - 0s 349us/step - loss: 0.0589 - categorical_accuracy: 0.7080 - val_loss: 0.1077 - val_categorical_accuracy: 0.3409\n",
      "Epoch 129/200\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0589 - categorical_accuracy: 0.7004 - val_loss: 0.1078 - val_categorical_accuracy: 0.3333\n",
      "Epoch 130/200\n",
      "524/524 [==============================] - 0s 310us/step - loss: 0.0584 - categorical_accuracy: 0.7061 - val_loss: 0.1077 - val_categorical_accuracy: 0.3636\n",
      "Epoch 131/200\n",
      "524/524 [==============================] - 0s 284us/step - loss: 0.0582 - categorical_accuracy: 0.7080 - val_loss: 0.1080 - val_categorical_accuracy: 0.3409\n",
      "Epoch 132/200\n",
      "524/524 [==============================] - 0s 290us/step - loss: 0.0580 - categorical_accuracy: 0.6927 - val_loss: 0.1078 - val_categorical_accuracy: 0.3561\n",
      "Epoch 133/200\n",
      "524/524 [==============================] - 0s 301us/step - loss: 0.0577 - categorical_accuracy: 0.7137 - val_loss: 0.1079 - val_categorical_accuracy: 0.3636\n",
      "Epoch 134/200\n",
      "524/524 [==============================] - 0s 281us/step - loss: 0.0568 - categorical_accuracy: 0.7252 - val_loss: 0.1081 - val_categorical_accuracy: 0.3485\n",
      "Epoch 135/200\n",
      "524/524 [==============================] - 0s 369us/step - loss: 0.0575 - categorical_accuracy: 0.7271 - val_loss: 0.1080 - val_categorical_accuracy: 0.3485\n",
      "Epoch 136/200\n",
      "524/524 [==============================] - 0s 294us/step - loss: 0.0566 - categorical_accuracy: 0.7195 - val_loss: 0.1082 - val_categorical_accuracy: 0.3409\n",
      "Epoch 137/200\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0569 - categorical_accuracy: 0.6947 - val_loss: 0.1081 - val_categorical_accuracy: 0.3485\n",
      "Epoch 138/200\n",
      "524/524 [==============================] - 0s 313us/step - loss: 0.0563 - categorical_accuracy: 0.7118 - val_loss: 0.1081 - val_categorical_accuracy: 0.3561\n",
      "Epoch 139/200\n",
      "524/524 [==============================] - 0s 331us/step - loss: 0.0559 - categorical_accuracy: 0.7309 - val_loss: 0.1083 - val_categorical_accuracy: 0.3561\n",
      "Epoch 140/200\n",
      "524/524 [==============================] - 0s 301us/step - loss: 0.0557 - categorical_accuracy: 0.7443 - val_loss: 0.1082 - val_categorical_accuracy: 0.3409\n",
      "Epoch 141/200\n",
      "524/524 [==============================] - 0s 304us/step - loss: 0.0561 - categorical_accuracy: 0.7099 - val_loss: 0.1083 - val_categorical_accuracy: 0.3409\n",
      "Epoch 142/200\n",
      "524/524 [==============================] - 0s 301us/step - loss: 0.0554 - categorical_accuracy: 0.7481 - val_loss: 0.1084 - val_categorical_accuracy: 0.3485\n",
      "Epoch 143/200\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0551 - categorical_accuracy: 0.7328 - val_loss: 0.1084 - val_categorical_accuracy: 0.3485\n",
      "Epoch 144/200\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0550 - categorical_accuracy: 0.7290 - val_loss: 0.1086 - val_categorical_accuracy: 0.3409\n",
      "Epoch 145/200\n",
      "524/524 [==============================] - 0s 313us/step - loss: 0.0546 - categorical_accuracy: 0.7405 - val_loss: 0.1085 - val_categorical_accuracy: 0.3409\n",
      "Epoch 146/200\n",
      "524/524 [==============================] - 0s 295us/step - loss: 0.0548 - categorical_accuracy: 0.7290 - val_loss: 0.1085 - val_categorical_accuracy: 0.3409\n",
      "Epoch 147/200\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0545 - categorical_accuracy: 0.7500 - val_loss: 0.1087 - val_categorical_accuracy: 0.3409\n",
      "Epoch 148/200\n",
      "524/524 [==============================] - 0s 323us/step - loss: 0.0541 - categorical_accuracy: 0.7576 - val_loss: 0.1088 - val_categorical_accuracy: 0.3409\n",
      "Epoch 149/200\n",
      "524/524 [==============================] - 0s 286us/step - loss: 0.0535 - categorical_accuracy: 0.7366 - val_loss: 0.1090 - val_categorical_accuracy: 0.3409\n",
      "Epoch 150/200\n",
      "524/524 [==============================] - 0s 312us/step - loss: 0.0544 - categorical_accuracy: 0.7462 - val_loss: 0.1091 - val_categorical_accuracy: 0.3485\n",
      "Epoch 151/200\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0536 - categorical_accuracy: 0.7729 - val_loss: 0.1091 - val_categorical_accuracy: 0.3409\n",
      "Epoch 152/200\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0529 - categorical_accuracy: 0.7576 - val_loss: 0.1092 - val_categorical_accuracy: 0.3485\n",
      "Epoch 153/200\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0522 - categorical_accuracy: 0.7557 - val_loss: 0.1094 - val_categorical_accuracy: 0.3485\n",
      "Epoch 154/200\n",
      "524/524 [==============================] - 0s 279us/step - loss: 0.0533 - categorical_accuracy: 0.7615 - val_loss: 0.1094 - val_categorical_accuracy: 0.3409\n",
      "Epoch 155/200\n",
      "524/524 [==============================] - 0s 325us/step - loss: 0.0526 - categorical_accuracy: 0.7615 - val_loss: 0.1094 - val_categorical_accuracy: 0.3485\n",
      "Epoch 156/200\n",
      "524/524 [==============================] - 0s 307us/step - loss: 0.0524 - categorical_accuracy: 0.7538 - val_loss: 0.1095 - val_categorical_accuracy: 0.3485\n",
      "Epoch 157/200\n",
      "524/524 [==============================] - 0s 314us/step - loss: 0.0526 - categorical_accuracy: 0.7519 - val_loss: 0.1096 - val_categorical_accuracy: 0.3485\n",
      "Epoch 158/200\n",
      "524/524 [==============================] - 0s 295us/step - loss: 0.0525 - categorical_accuracy: 0.7634 - val_loss: 0.1097 - val_categorical_accuracy: 0.3485\n",
      "Epoch 159/200\n",
      "524/524 [==============================] - 0s 299us/step - loss: 0.0516 - categorical_accuracy: 0.7691 - val_loss: 0.1098 - val_categorical_accuracy: 0.3485\n",
      "Epoch 160/200\n",
      "524/524 [==============================] - 0s 309us/step - loss: 0.0519 - categorical_accuracy: 0.7710 - val_loss: 0.1100 - val_categorical_accuracy: 0.3485\n",
      "Epoch 161/200\n",
      "524/524 [==============================] - 0s 291us/step - loss: 0.0509 - categorical_accuracy: 0.7805 - val_loss: 0.1099 - val_categorical_accuracy: 0.3561\n",
      "Epoch 162/200\n",
      "524/524 [==============================] - 0s 315us/step - loss: 0.0512 - categorical_accuracy: 0.7767 - val_loss: 0.1100 - val_categorical_accuracy: 0.3561\n",
      "Epoch 163/200\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0509 - categorical_accuracy: 0.7634 - val_loss: 0.1103 - val_categorical_accuracy: 0.3561\n",
      "Epoch 164/200\n",
      "524/524 [==============================] - 0s 317us/step - loss: 0.0506 - categorical_accuracy: 0.7767 - val_loss: 0.1102 - val_categorical_accuracy: 0.3561\n",
      "Epoch 165/200\n",
      "524/524 [==============================] - 0s 319us/step - loss: 0.0504 - categorical_accuracy: 0.7729 - val_loss: 0.1104 - val_categorical_accuracy: 0.3561\n",
      "Epoch 166/200\n",
      "524/524 [==============================] - 0s 299us/step - loss: 0.0507 - categorical_accuracy: 0.7672 - val_loss: 0.1104 - val_categorical_accuracy: 0.3636\n",
      "Epoch 167/200\n",
      "524/524 [==============================] - 0s 287us/step - loss: 0.0507 - categorical_accuracy: 0.7786 - val_loss: 0.1106 - val_categorical_accuracy: 0.3636\n",
      "Epoch 168/200\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0501 - categorical_accuracy: 0.7939 - val_loss: 0.1105 - val_categorical_accuracy: 0.3636\n",
      "Epoch 169/200\n",
      "524/524 [==============================] - 0s 295us/step - loss: 0.0502 - categorical_accuracy: 0.7786 - val_loss: 0.1105 - val_categorical_accuracy: 0.3636\n",
      "Epoch 170/200\n",
      "524/524 [==============================] - 0s 298us/step - loss: 0.0493 - categorical_accuracy: 0.7977 - val_loss: 0.1106 - val_categorical_accuracy: 0.3636\n",
      "Epoch 171/200\n",
      "524/524 [==============================] - 0s 314us/step - loss: 0.0497 - categorical_accuracy: 0.7844 - val_loss: 0.1109 - val_categorical_accuracy: 0.3636\n",
      "Epoch 172/200\n",
      "524/524 [==============================] - 0s 345us/step - loss: 0.0499 - categorical_accuracy: 0.7958 - val_loss: 0.1110 - val_categorical_accuracy: 0.3561\n",
      "Epoch 173/200\n",
      "524/524 [==============================] - 0s 305us/step - loss: 0.0497 - categorical_accuracy: 0.7805 - val_loss: 0.1110 - val_categorical_accuracy: 0.3561\n",
      "Epoch 174/200\n",
      "524/524 [==============================] - 0s 300us/step - loss: 0.0495 - categorical_accuracy: 0.7805 - val_loss: 0.1111 - val_categorical_accuracy: 0.3636\n",
      "Epoch 175/200\n",
      "524/524 [==============================] - 0s 305us/step - loss: 0.0489 - categorical_accuracy: 0.7844 - val_loss: 0.1113 - val_categorical_accuracy: 0.3636\n",
      "Epoch 176/200\n",
      "524/524 [==============================] - 0s 306us/step - loss: 0.0492 - categorical_accuracy: 0.7920 - val_loss: 0.1114 - val_categorical_accuracy: 0.3636\n",
      "Epoch 177/200\n",
      "524/524 [==============================] - 0s 304us/step - loss: 0.0493 - categorical_accuracy: 0.7748 - val_loss: 0.1115 - val_categorical_accuracy: 0.3561\n",
      "Epoch 178/200\n",
      "524/524 [==============================] - 0s 289us/step - loss: 0.0480 - categorical_accuracy: 0.7958 - val_loss: 0.1117 - val_categorical_accuracy: 0.3561\n",
      "Epoch 179/200\n",
      "524/524 [==============================] - 0s 311us/step - loss: 0.0480 - categorical_accuracy: 0.8130 - val_loss: 0.1117 - val_categorical_accuracy: 0.3561\n",
      "Epoch 180/200\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0478 - categorical_accuracy: 0.8092 - val_loss: 0.1117 - val_categorical_accuracy: 0.3561\n",
      "Epoch 181/200\n",
      "524/524 [==============================] - 0s 305us/step - loss: 0.0476 - categorical_accuracy: 0.8130 - val_loss: 0.1118 - val_categorical_accuracy: 0.3636\n",
      "Epoch 182/200\n",
      "524/524 [==============================] - 0s 349us/step - loss: 0.0473 - categorical_accuracy: 0.8168 - val_loss: 0.1119 - val_categorical_accuracy: 0.3561\n",
      "Epoch 183/200\n",
      "524/524 [==============================] - 0s 296us/step - loss: 0.0472 - categorical_accuracy: 0.8149 - val_loss: 0.1120 - val_categorical_accuracy: 0.3636\n",
      "Epoch 184/200\n",
      "524/524 [==============================] - 0s 314us/step - loss: 0.0472 - categorical_accuracy: 0.8168 - val_loss: 0.1122 - val_categorical_accuracy: 0.3636\n",
      "Epoch 185/200\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0463 - categorical_accuracy: 0.8168 - val_loss: 0.1123 - val_categorical_accuracy: 0.3636\n",
      "Epoch 186/200\n",
      "524/524 [==============================] - 0s 286us/step - loss: 0.0470 - categorical_accuracy: 0.8053 - val_loss: 0.1125 - val_categorical_accuracy: 0.3636\n",
      "Epoch 187/200\n",
      "524/524 [==============================] - 0s 327us/step - loss: 0.0471 - categorical_accuracy: 0.7882 - val_loss: 0.1126 - val_categorical_accuracy: 0.3636\n",
      "Epoch 188/200\n",
      "524/524 [==============================] - 0s 338us/step - loss: 0.0467 - categorical_accuracy: 0.8168 - val_loss: 0.1126 - val_categorical_accuracy: 0.3636\n",
      "Epoch 189/200\n",
      "524/524 [==============================] - 0s 318us/step - loss: 0.0475 - categorical_accuracy: 0.8111 - val_loss: 0.1126 - val_categorical_accuracy: 0.3636\n",
      "Epoch 190/200\n",
      "524/524 [==============================] - 0s 340us/step - loss: 0.0463 - categorical_accuracy: 0.8111 - val_loss: 0.1129 - val_categorical_accuracy: 0.3636\n",
      "Epoch 191/200\n",
      "524/524 [==============================] - 0s 313us/step - loss: 0.0462 - categorical_accuracy: 0.8187 - val_loss: 0.1129 - val_categorical_accuracy: 0.3561\n",
      "Epoch 192/200\n",
      "524/524 [==============================] - 0s 352us/step - loss: 0.0461 - categorical_accuracy: 0.8206 - val_loss: 0.1130 - val_categorical_accuracy: 0.3636\n",
      "Epoch 193/200\n",
      "524/524 [==============================] - 0s 328us/step - loss: 0.0456 - categorical_accuracy: 0.8359 - val_loss: 0.1131 - val_categorical_accuracy: 0.3561\n",
      "Epoch 194/200\n",
      "524/524 [==============================] - 0s 333us/step - loss: 0.0465 - categorical_accuracy: 0.8092 - val_loss: 0.1134 - val_categorical_accuracy: 0.3561\n",
      "Epoch 195/200\n",
      "524/524 [==============================] - 0s 343us/step - loss: 0.0463 - categorical_accuracy: 0.8073 - val_loss: 0.1134 - val_categorical_accuracy: 0.3561\n",
      "Epoch 196/200\n",
      "524/524 [==============================] - 0s 284us/step - loss: 0.0457 - categorical_accuracy: 0.8359 - val_loss: 0.1136 - val_categorical_accuracy: 0.3561\n",
      "Epoch 197/200\n",
      "524/524 [==============================] - 0s 311us/step - loss: 0.0450 - categorical_accuracy: 0.8168 - val_loss: 0.1138 - val_categorical_accuracy: 0.3561\n",
      "Epoch 198/200\n",
      "524/524 [==============================] - 0s 336us/step - loss: 0.0452 - categorical_accuracy: 0.8187 - val_loss: 0.1139 - val_categorical_accuracy: 0.3636\n",
      "Epoch 199/200\n",
      "524/524 [==============================] - 0s 311us/step - loss: 0.0447 - categorical_accuracy: 0.8435 - val_loss: 0.1140 - val_categorical_accuracy: 0.3561\n",
      "Epoch 200/200\n",
      "524/524 [==============================] - 0s 334us/step - loss: 0.0446 - categorical_accuracy: 0.8321 - val_loss: 0.1139 - val_categorical_accuracy: 0.3636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd4d3714cc0>"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypreds_int = np.zeros_like(ypreds)\n",
    "ypreds_int[ypreds>=0.5] = 1\n",
    "ypreds_int[ypreds<0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.7931244e-03, 3.9255321e-03, 1.4305204e-02, ..., 1.0032922e-02,\n",
       "        1.1538655e-02, 4.7504604e-03],\n",
       "       [4.3094158e-04, 2.8300285e-04, 8.6039305e-04, ..., 6.5535307e-05,\n",
       "        1.7729402e-04, 3.1057894e-03],\n",
       "       [2.3993820e-02, 2.3756027e-03, 5.2696198e-02, ..., 3.1572282e-03,\n",
       "        4.3440163e-03, 5.6802630e-03],\n",
       "       ...,\n",
       "       [3.0794740e-04, 1.3528466e-03, 2.9908836e-02, ..., 1.3589859e-03,\n",
       "        5.5104494e-04, 8.3342195e-04],\n",
       "       [1.2870729e-03, 4.3887645e-02, 8.8682771e-04, ..., 1.5146434e-02,\n",
       "        4.7052205e-03, 4.9856305e-04],\n",
       "       [8.0657601e-03, 1.7917335e-02, 6.7669153e-04, ..., 1.5256833e-03,\n",
       "        1.1959722e-03, 5.6374277e-04]], dtype=float32)"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3,   3,   7,   9,   9,  12,  13,  16,  18,  18,  21,  23,  24,\n",
       "         24,  24,  25,  31,  34,  39,  40,  41,  42,  42,  43,  45,  46,\n",
       "         50,  50,  51,  53,  54,  56,  57,  60,  61,  64,  65,  66,  67,\n",
       "         72,  74,  75,  77,  80,  92,  92,  96,  97,  99, 100, 106, 110,\n",
       "        114, 120, 122, 123, 124, 129]),\n",
       " array([ 2, 15, 40, 17, 39,  0,  4, 42,  6, 17, 37, 33, 19, 25, 34,  2,  0,\n",
       "        12, 27, 13, 12,  6, 17, 17, 25, 25, 17, 33,  8, 32, 25,  4, 17, 20,\n",
       "        21, 17,  4, 36,  4, 12, 37, 13, 19, 33,  6, 33, 42, 27, 17, 20, 13,\n",
       "        32, 12, 17, 39, 10, 20, 20]))"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(ypreds_int == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2920353982300885"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, ypreds_int, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEST MLP PIPELINE\n",
    "pipeline_mlp = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=100, random_state=1)),\n",
    "            ('MLP', MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(100),random_state=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, vocabs_train, vocabs_test = train_test_split(X, Y_mlb, vocabs, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.25, max_features=None, min_df=0.0025,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf...True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False))])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "pipeline_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probas = pipeline_mlp.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.61084114e-26, 3.03420474e-28, 1.97892467e-38, ...,\n",
       "        6.45401528e-29, 4.43539277e-38, 1.25558894e-34],\n",
       "       [1.35484764e-13, 1.18487097e-56, 1.98329224e-41, ...,\n",
       "        6.35343769e-11, 4.07530161e-10, 1.88383652e-52],\n",
       "       [1.76924771e-25, 3.42626342e-34, 1.11219954e-49, ...,\n",
       "        2.56725686e-34, 4.22418826e-47, 2.40280405e-37],\n",
       "       ...,\n",
       "       [6.53904933e-52, 8.00590038e-31, 3.38471659e-37, ...,\n",
       "        9.24587112e-28, 2.09201948e-39, 1.20330368e-46],\n",
       "       [3.95278898e-84, 3.23055830e-38, 6.55220352e-72, ...,\n",
       "        1.77668911e-33, 4.14978945e-97, 1.34202954e-86],\n",
       "       [1.16159507e-26, 5.16314801e-25, 2.24881456e-53, ...,\n",
       "        2.80328582e-30, 7.04062310e-55, 2.66813690e-27]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one tag for each prediction by the highest value in the predicted vector\n",
    "row_maxs = y_pred_probas.max(axis=1, keepdims=True)\n",
    "# Indices of maximum value for each row\n",
    "y_pred1 = np.where(y_pred_probas == row_maxs, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Society',), ('RDF',), ('Services',), ('Environment',), ('Services',)]\n",
      "[('API',), ('RDF',), ('Security',), ('Time',), ('Society',)]\n",
      "['wdrs' 'rr' 'algo' 'interval' 'comm']\n"
     ]
    }
   ],
   "source": [
    "# Compare prediction and true label\n",
    "print(mlb.inverse_transform(y_pred1[:5]))\n",
    "print(mlb.inverse_transform(y_test[:5]))\n",
    "print(vocabs_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.54885587e-120 4.02558368e-033 4.97503419e-049 5.88969552e-042\n",
      " 1.53312744e-071 2.28532802e-127 1.70999415e-094 1.06012728e-075\n",
      " 5.04039157e-063 1.63265017e-037 4.36245761e-098 7.02502911e-054\n",
      " 7.30329951e-092 3.08354532e-057 6.37495054e-116 2.31459374e-062\n",
      " 1.27203227e-082 3.03122087e-105 1.59619395e-086 3.35553572e-066\n",
      " 9.99999999e-001 4.90648356e-077 1.08729097e-073 5.49531645e-032\n",
      " 9.07680576e-053 1.21609655e-106 4.90804301e-051 3.36449920e-006\n",
      " 1.10067037e-060 3.58686655e-046 1.89011519e-028 3.55901399e-145\n",
      " 1.06019624e-102 1.47854944e-059 7.19587903e-098 2.99722375e-014\n",
      " 5.51782322e-062 8.25005058e-058 3.03752267e-067 2.98471665e-086\n",
      " 6.40590116e-045 1.28706158e-083 2.42568169e-047]\n",
      "(array([20]),)\n"
     ]
    }
   ],
   "source": [
    "# It seems that labels are predicted if value of neuron > 0.5\n",
    "print(y_pred_probas[4])\n",
    "print(np.where(y_pred[4] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26459143968871596\n",
      "0.35051546391752575\n",
      "0.25569895221058014\n",
      "0.2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "print(precision_score(y_test, y_pred, average=\"micro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_metric(y_true, y_pred_proba):\n",
    "    # Keep only one label with the higher proba\n",
    "    row_maxs = y_pred_proba.max(axis=1, keepdims=True)\n",
    "    # Indices of maximum value for each row\n",
    "    maxis = np.where(y_pred_proba == row_maxs, 1, 0)\n",
    "    # 1 if max value is indeed a tag, 0 otherwise\n",
    "    check = y_true[maxis == 1]\n",
    "    return np.mean(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35365853658536583\n"
     ]
    }
   ],
   "source": [
    "print(cust_metric(y_test, y_pred_probas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "########### TRAIN MODEL WITH ALL DATA ###########\n",
    "#################################################\n",
    "\n",
    "pipeline_mlp = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=100, random_state=1)),\n",
    "            ('MLP', MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(100),random_state=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.25, max_features=None, min_df=0.0025,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf...True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_mlp.fit(X, Y_mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_mlp.predict([\"events all the events i love\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlb.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save pipeline and mlb transformer\n",
    "joblib.dump(pipeline_mlp, \"clf.pkl\")\n",
    "\n",
    "joblib.dump(mlb, \"mlb.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9906542056074766\n",
      "0.9875776397515528\n",
      "0.8772609819121449\n",
      "0.99375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Prediction on train set\n",
    "y_pred = pipeline_mlp.predict(X_test)\n",
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "print(precision_score(y_test, y_pred, average=\"micro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_pred[:4])\n",
    "#print(y_test[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN ALL DATA ON SVC (One-vs-Rest and class balanced)\n",
    "pipeline_svc = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=100, random_state=1)),\n",
    "            ('SVC', OneVsRestClassifier(SVC(C=10, gamma=1, kernel=\"rbf\", decision_function_shape='ovo',class_weight=\"balanced\", probability=True)))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.25, max_features=None, min_df=0.0025,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf...ility=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=None))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_svc.fit(X, Y_mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew_pred = pipeline_svc.predict(Xnew)\n",
    "ynew_predProba = pipeline_svc.predict_proba(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8664850136239782\n",
      "0.7681159420289855\n",
      "0.718175493756889\n",
      "0.99375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mondeca/applications/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Prediction on train set\n",
    "y_pred = pipeline_svc.predict(X_test)\n",
    "print(f1_score(y_test, y_pred, average='micro'))\n",
    "print(precision_score(y_test, y_pred, average=\"micro\"))\n",
    "print(precision_score(y_test, y_pred, average=\"macro\"))\n",
    "print(recall_score(y_test, y_pred, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Load new LoV vocabs #\n",
    "#######################\n",
    "\n",
    "with open('newDATA.pkl', 'rb') as handle:\n",
    "    Xnew, vocabs = pickle.load(handle)\n",
    "    \n",
    "Xnew = np.array(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def getTags(pipeline, Xdata):\n",
    "    ynew_pred = pipeline.predict(Xnew)\n",
    "    ynew_predProba = pipeline.predict_proba(Xnew)\n",
    "    \n",
    "    # Get one tag for each prediction by the highest value in the predicted vector\n",
    "    row_maxs = ynew_predProba.max(axis=1, keepdims=True)\n",
    "    # Indices of maximum value for each row\n",
    "    ynew_pred1 = np.where(ynew_predProba == row_maxs, 1, 0)\n",
    "    \n",
    "    print(vocabs)\n",
    "    newPreds = mlb.inverse_transform(ynew_pred)\n",
    "    newPreds1 = mlb.inverse_transform(ynew_pred1)\n",
    "    \n",
    "    pp = pprint.PrettyPrinter()\n",
    "    pp.pprint([(x,y,z) for x,y,z in zip(vocabs, newPreds, newPreds1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UsabilityOntology.rdf', 'cultural-event.owl', 'munc.owl', 'catalogue.owl', 'terms.ttl', 'denotative-description.owl', 'context-description.owl', 'ontology.ttl', 'location.owl', 'core.owl', 'vir.ttl', 'arco.owl']\n",
      "[('UsabilityOntology.rdf', (), ('API',)),\n",
      " ('cultural-event.owl', ('Events', 'Multimedia'), ('Events',)),\n",
      " ('munc.owl', ('RDF',), ('RDF',)),\n",
      " ('catalogue.owl', ('Catalogs', 'Government'), ('Government',)),\n",
      " ('terms.ttl', ('General & Upper', 'Services'), ('General & Upper',)),\n",
      " ('denotative-description.owl',\n",
      "  ('Catalogs', 'Events', 'Government'),\n",
      "  ('Catalogs',)),\n",
      " ('context-description.owl',\n",
      "  ('Catalogs', 'Events', 'Multimedia'),\n",
      "  ('Catalogs',)),\n",
      " ('ontology.ttl', ('Industry', 'Services'), ('Industry',)),\n",
      " ('location.owl', (), ('Events',)),\n",
      " ('core.owl', ('Events',), ('Events',)),\n",
      " ('vir.ttl', (), ('Support',)),\n",
      " ('arco.owl', ('Catalogs', 'Events', 'Multimedia'), ('Catalogs',))]\n"
     ]
    }
   ],
   "source": [
    "getTags(pipeline_mlp, Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UsabilityOntology.rdf', 'cultural-event.owl', 'munc.owl', 'catalogue.owl', 'terms.ttl', 'denotative-description.owl', 'context-description.owl', 'ontology.ttl', 'location.owl', 'core.owl', 'vir.ttl', 'arco.owl']\n",
      "[('UsabilityOntology.rdf', (), ('API',)),\n",
      " ('cultural-event.owl',\n",
      "  ('Catalogs', 'Events', 'Government', 'Multimedia'),\n",
      "  ('Catalogs',)),\n",
      " ('munc.owl', (), ('RDF',)),\n",
      " ('catalogue.owl',\n",
      "  ('Catalogs', 'Events', 'Government', 'Multimedia'),\n",
      "  ('Catalogs',)),\n",
      " ('terms.ttl', ('General & Upper', 'RDF', 'Services'), ('RDF',)),\n",
      " ('denotative-description.owl',\n",
      "  ('Catalogs', 'Environment', 'Events', 'Government', 'Multimedia'),\n",
      "  ('Catalogs',)),\n",
      " ('context-description.owl',\n",
      "  ('Catalogs', 'Environment', 'Events', 'Government', 'Multimedia'),\n",
      "  ('Catalogs',)),\n",
      " ('ontology.ttl', ('Industry', 'Services'), ('Industry',)),\n",
      " ('location.owl',\n",
      "  ('Catalogs', 'Events', 'Government', 'Multimedia'),\n",
      "  ('Catalogs',)),\n",
      " ('core.owl',\n",
      "  ('Catalogs', 'Events', 'Government', 'Multimedia'),\n",
      "  ('Catalogs',)),\n",
      " ('vir.ttl', (), ('Support',)),\n",
      " ('arco.owl',\n",
      "  ('Catalogs', 'Environment', 'Events', 'Government', 'Multimedia'),\n",
      "  ('Catalogs',))]\n"
     ]
    }
   ],
   "source": [
    "getTags(pipeline_svc, Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one tag for each prediction by the highest value in the predicted vector\n",
    "row_maxs = ynew_predProba.max(axis=1, keepdims=True)\n",
    "# Indices of maximum value for each row\n",
    "ynew_pred1 = np.where(ynew_predProba == row_maxs, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UsabilityOntology.rdf', 'cultural-event.owl', 'munc.owl', 'catalogue.owl', 'terms.ttl', 'denotative-description.owl', 'context-description.owl', 'ontology.ttl', 'location.owl', 'core.owl', 'vir.ttl', 'arco.owl']\n"
     ]
    }
   ],
   "source": [
    "print(vocabs)\n",
    "newPreds = mlb.inverse_transform(ynew_pred)\n",
    "newPreds1 = mlb.inverse_transform(ynew_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('UsabilityOntology.rdf', (), ('API',)),\n",
       " ('cultural-event.owl', ('Events', 'Multimedia'), ('Events',)),\n",
       " ('munc.owl', ('RDF',), ('RDF',)),\n",
       " ('catalogue.owl', ('Catalogs', 'Government'), ('Government',)),\n",
       " ('terms.ttl', ('General & Upper', 'Services'), ('General & Upper',)),\n",
       " ('denotative-description.owl',\n",
       "  ('Catalogs', 'Events', 'Government'),\n",
       "  ('Catalogs',)),\n",
       " ('context-description.owl',\n",
       "  ('Catalogs', 'Events', 'Multimedia'),\n",
       "  ('Catalogs',)),\n",
       " ('ontology.ttl', ('Industry', 'Services'), ('Industry',)),\n",
       " ('location.owl', (), ('Events',)),\n",
       " ('core.owl', ('Events',), ('Events',)),\n",
       " ('vir.ttl', (), ('Support',)),\n",
       " ('arco.owl', ('Catalogs', 'Events', 'Multimedia'), ('Catalogs',))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x,y,z) for x,y,z in zip(vocabs, newPreds, newPreds1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST RANDOM FOREST\n",
    "pipeline_RF = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "            ('svd', TruncatedSVD(algorithm='randomized', n_components=100, random_state=1)),\n",
    "            ('RF', RandomForestClassifier(n_estimators=200, random_state=1, n_jobs=50))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.25, max_features=None, min_df=0.0025,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf...timators=200, n_jobs=50,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "pipeline_RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probas = pipeline_RF.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 43)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probas_proc = np.array(y_pred_probas)\n",
    "y_pred_probas_proc = y_pred_probas_proc[:,:,1].T\n",
    "y_pred_probas_proc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04 , 0.02 , 0.005, ..., 0.03 , 0.025, 0.   ],\n",
       "       [0.15 , 0.01 , 0.005, ..., 0.075, 0.065, 0.   ],\n",
       "       [0.02 , 0.005, 0.035, ..., 0.035, 0.015, 0.005],\n",
       "       ...,\n",
       "       [0.015, 0.01 , 0.015, ..., 0.055, 0.03 , 0.   ],\n",
       "       [0.02 , 0.005, 0.   , ..., 0.02 , 0.   , 0.005],\n",
       "       [0.04 , 0.06 , 0.015, ..., 0.015, 0.01 , 0.01 ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probas_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 43)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probas_proc.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(cust_metric(y_test, y_pred_probas_proc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "############## DOC2VEC approach #################\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "# Split (get explicit labels and no mlb)\n",
    "X_train, X_test, y_train, y_test, vocabs_train, vocabs_test = train_test_split(X, Y, vocabs, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged = [TaggedDocument(words = Tokenizer(doc), tags=tags) for doc, tags in zip(X_train, y_train)]\n",
    "test_tagged = [TaggedDocument(words = Tokenizer(doc), tags=tags) for doc, tags in zip(X_test, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 524/524 [00:00<00:00, 1213592.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Building vocab\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, window = 5,  negative=10, hs=0, min_count=2, sample = 0, workers=cores, seed=0)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 1s, sys: 625 ms, total: 3min 2s\n",
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_dbow.train(train_tagged, total_examples=len(train_tagged), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text \n",
    "def doc_to_vec(X_tagged):\n",
    "    vect = [model_dbow.infer_vector(x[0]) for x in X_tagged]\n",
    "    return np.array(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = doc_to_vec(train_tagged)\n",
    "X_test_vect = doc_to_vec(test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524, 300)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mlb = mlb.transform(y_train)\n",
    "y_test_mlb = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train_mlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs',alpha=1e-5,hidden_layer_sizes=(200, 100),random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train_vect, y_train_mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test_vect)\n",
    "y_pred_proba = mlp.predict_proba(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29687499999999994"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_mlb, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3106060606060606"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_metric(y_test_mlb, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0, n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train_vect, y_train_mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test_vect)\n",
    "y_pred_proba = rf.predict_proba(X_test_vect)\n",
    "y_pred_probas_proc = np.array(y_pred_probas)\n",
    "y_pred_probas_proc = y_pred_probas_proc[:,:,1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03592814371257485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f1_score(y_test_mlb, y_pred, average=\"micro\"))\n",
    "cust_metric(y_test_mlb, y_pred_probas_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRID SEARCH FOR SVC ####\n",
    "\n",
    "svc = OneVsRestClassifier(SVC(class_weight=\"balanced\"), n_jobs=-1)\n",
    "            \n",
    "params={'estimator__C':[1, 5, 10],\n",
    "        'estimator__kernel':[\"rbf\", \"sigmoid\", \"linear\"],\n",
    "        'estimator__gamma':['auto', 1, 2],\n",
    "        'estimator__decision_function_shape' : [\"ovo\", \"ovr\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['estimator__C', 'estimator__cache_size', 'estimator__class_weight', 'estimator__coef0', 'estimator__decision_function_shape', 'estimator__degree', 'estimator__gamma', 'estimator__kernel', 'estimator__max_iter', 'estimator__probability', 'estimator__random_state', 'estimator__shrinking', 'estimator__tol', 'estimator__verbose', 'estimator', 'n_jobs'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=OneVsRestClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "          n_jobs=-1),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'estimator__C': [1, 5, 10], 'estimator__kernel': ['rbf', 'sigmoid', 'linear'], 'estimator__gamma': ['auto', 1, 2], 'estimator__decision_function_shape': ['ovo', 'ovr']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='f1_micro', verbose=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(svc, params, cv=3, scoring=\"f1_micro\")\n",
    "gs.fit(X_proc,Y_mlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 5,\n",
       " 'estimator__decision_function_shape': 'ovo',\n",
       " 'estimator__gamma': 'auto',\n",
       " 'estimator__kernel': 'linear'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
